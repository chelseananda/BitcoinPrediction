{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOa7ZgPepE2JSC/lVp3gE6b"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_5BbklG2O1qF","outputId":"379c0a6b-9f10-4230-d23d-2e209e3f5a04"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: swig in /usr/local/lib/python3.10/dist-packages (4.1.1.post0)\n","Requirement already satisfied: wrds in /usr/local/lib/python3.10/dist-packages (3.1.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from wrds) (1.23.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from wrds) (1.5.3)\n","Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.10/dist-packages (from wrds) (2.9.9)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from wrds) (1.11.3)\n","Requirement already satisfied: sqlalchemy<2 in /usr/local/lib/python3.10/dist-packages (from wrds) (1.4.50)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<2->wrds) (3.0.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->wrds) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->wrds) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->wrds) (1.16.0)\n","Requirement already satisfied: pyportfolioopt in /usr/local/lib/python3.10/dist-packages (1.5.5)\n","Requirement already satisfied: cvxpy<2.0.0,>=1.1.19 in /usr/local/lib/python3.10/dist-packages (from pyportfolioopt) (1.3.2)\n","Requirement already satisfied: numpy<2.0.0,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pyportfolioopt) (1.23.5)\n","Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.10/dist-packages (from pyportfolioopt) (1.5.3)\n","Requirement already satisfied: scipy<2.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from pyportfolioopt) (1.11.3)\n","Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (0.6.2.post8)\n","Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (2.0.12)\n","Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (3.2.4)\n","Requirement already satisfied: setuptools>65.5.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (67.7.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pyportfolioopt) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pyportfolioopt) (2023.3.post1)\n","Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.4.1->cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (0.1.7.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.19->pyportfolioopt) (1.16.0)\n","Collecting git+https://github.com/AI4Finance-Foundation/FinRL.git\n","  Cloning https://github.com/AI4Finance-Foundation/FinRL.git to /tmp/pip-req-build-561228_6\n","  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/FinRL.git /tmp/pip-req-build-561228_6\n","  Resolved https://github.com/AI4Finance-Foundation/FinRL.git to commit 55764e824c2e54686a6af7dba79a9d476aa30259\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl (from finrl==0.3.6)\n","  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-kzz0rr1y/elegantrl_f8fc768ab0ef4892b4abff59bf43db7f\n","  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-kzz0rr1y/elegantrl_f8fc768ab0ef4892b4abff59bf43db7f\n","  Resolved https://github.com/AI4Finance-Foundation/ElegantRL.git to commit dde7ee4daa226450a43280e4ee02f1f23b565aa2\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: alpaca-trade-api<4,>=3 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (3.0.2)\n","Requirement already satisfied: ccxt<4,>=3 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (3.1.60)\n","Requirement already satisfied: exchange-calendars<5,>=4 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (4.5)\n","Requirement already satisfied: jqdatasdk<2,>=1 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (1.9.2)\n","Requirement already satisfied: pyfolio<0.10,>=0.9 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (0.9.2)\n","Requirement already satisfied: pyportfolioopt<2,>=1 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (1.5.5)\n","Requirement already satisfied: ray[default,tune]<3,>=2 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (2.8.0)\n","Requirement already satisfied: scikit-learn<2,>=1 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (1.2.2)\n","Requirement already satisfied: stable-baselines3[extra]>=2.0.0a5 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (2.2.1)\n","Requirement already satisfied: stockstats<0.6,>=0.5 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (0.5.4)\n","Requirement already satisfied: wrds<4,>=3 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (3.1.6)\n","Requirement already satisfied: yfinance<0.3,>=0.2 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (0.2.31)\n","Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.5.3)\n","Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.23.5)\n","Requirement already satisfied: requests<3,>2 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (2.31.0)\n","Requirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.26.18)\n","Requirement already satisfied: websocket-client<2,>=0.56.0 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.6.4)\n","Requirement already satisfied: websockets<11,>=9.0 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (10.4)\n","Requirement already satisfied: msgpack==1.0.3 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.0.3)\n","Requirement already satisfied: aiohttp==3.8.2 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (3.8.2)\n","Requirement already satisfied: PyYAML==6.0 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (6.0)\n","Requirement already satisfied: deprecation==2.1.0 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (2.1.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.2->alpaca-trade-api<4,>=3->finrl==0.3.6) (23.1.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.2->alpaca-trade-api<4,>=3->finrl==0.3.6) (2.1.1)\n","Requirement already satisfied: multidict<6.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.2->alpaca-trade-api<4,>=3->finrl==0.3.6) (5.2.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.2->alpaca-trade-api<4,>=3->finrl==0.3.6) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.2->alpaca-trade-api<4,>=3->finrl==0.3.6) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.2->alpaca-trade-api<4,>=3->finrl==0.3.6) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.2->alpaca-trade-api<4,>=3->finrl==0.3.6) (1.3.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from deprecation==2.1.0->alpaca-trade-api<4,>=3->finrl==0.3.6) (23.2)\n","Requirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.10/dist-packages (from ccxt<4,>=3->finrl==0.3.6) (67.7.2)\n","Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.10/dist-packages (from ccxt<4,>=3->finrl==0.3.6) (2023.7.22)\n","Requirement already satisfied: cryptography>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from ccxt<4,>=3->finrl==0.3.6) (41.0.5)\n","Requirement already satisfied: aiodns>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from ccxt<4,>=3->finrl==0.3.6) (3.1.1)\n","Requirement already satisfied: pyluach in /usr/local/lib/python3.10/dist-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (2.2.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (2.8.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (0.12.0)\n","Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (2023.3)\n","Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.10/dist-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (0.3.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (1.16.0)\n","Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.10/dist-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (1.4.50)\n","Requirement already satisfied: thriftpy2>=0.3.9 in /usr/local/lib/python3.10/dist-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (0.4.17)\n","Requirement already satisfied: pymysql>=0.7.6 in /usr/local/lib/python3.10/dist-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (1.1.0)\n","Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (7.34.0)\n","Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (3.7.1)\n","Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (2023.3.post1)\n","Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (1.11.3)\n","Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (0.12.2)\n","Requirement already satisfied: empyrical>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (0.5.5)\n","Requirement already satisfied: cvxpy<2.0.0,>=1.1.19 in /usr/local/lib/python3.10/dist-packages (from pyportfolioopt<2,>=1->finrl==0.3.6) (1.3.2)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (8.1.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (3.13.1)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (4.19.2)\n","Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (3.20.3)\n","Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.7.0)\n","Requirement already satisfied: colorful in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.5.5)\n","Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.3.14)\n","Requirement already satisfied: gpustat>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (1.1.1)\n","Requirement already satisfied: opencensus in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.11.3)\n","Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (1.10.13)\n","Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.18.0)\n","Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (6.4.0)\n","Requirement already satisfied: virtualenv<20.21.1,>=20.0.24 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (20.21.0)\n","Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (1.59.2)\n","Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (2.6.2.2)\n","Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (9.0.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (2023.6.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2,>=1->finrl==0.3.6) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2,>=1->finrl==0.3.6) (3.2.0)\n","Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.29.1)\n","Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.1.0+cu118)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.2.1)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.8.0.76)\n","Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.1.0)\n","Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.14.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (5.9.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.66.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (13.7.0)\n","Requirement already satisfied: shimmy[atari]~=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.3.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (9.4.0)\n","Requirement already satisfied: autorom[accept-rom-license]~=0.6.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.6.1)\n","Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.10/dist-packages (from wrds<4,>=3->finrl==0.3.6) (2.9.9)\n","Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (0.0.11)\n","Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (4.9.3)\n","Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (1.4.4)\n","Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (2.3.8)\n","Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (3.17.0)\n","Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (4.11.2)\n","Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (1.1)\n","Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.6) (0.25.2)\n","Requirement already satisfied: pycares>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from aiodns>=1.1.1->ccxt<4,>=3->finrl==0.3.6) (4.4.0)\n","Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.6.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance<0.3,>=0.2->finrl==0.3.6) (2.5)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.6) (1.16.0)\n","Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (0.6.2.post8)\n","Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (2.0.12)\n","Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (3.2.4)\n","Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.10/dist-packages (from empyrical>=0.5.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.10.0)\n","Requirement already satisfied: nvidia-ml-py>=11.450.129 in /usr/local/lib/python3.10/dist-packages (from gpustat>=1.0.0->ray[default,tune]<3,>=2->finrl==0.3.6) (12.535.133)\n","Requirement already satisfied: blessed>=1.17.1 in /usr/local/lib/python3.10/dist-packages (from gpustat>=1.0.0->ray[default,tune]<3,>=2->finrl==0.3.6) (1.20.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.5.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.0.4)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance<0.3,>=0.2->finrl==0.3.6) (0.5.1)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.19.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (3.0.41)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (4.8.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (4.44.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (3.1.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>2->alpaca-trade-api<4,>=3->finrl==0.3.6) (3.4)\n","Requirement already satisfied: ale-py~=0.8.1 in /usr/local/lib/python3.10/dist-packages (from shimmy[atari]~=1.3.0->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.8.1)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk<2,>=1->finrl==0.3.6) (3.0.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.4.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.5.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.0.1)\n","Requirement already satisfied: ply<4.0,>=3.4 in /usr/local/lib/python3.10/dist-packages (from thriftpy2>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.6) (3.11)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.1.0)\n","Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from virtualenv<20.21.1,>=20.0.24->ray[default,tune]<3,>=2->finrl==0.3.6) (0.3.7)\n","Requirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.10/dist-packages (from virtualenv<20.21.1,>=20.0.24->ray[default,tune]<3,>=2->finrl==0.3.6) (3.11.0)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.6) (0.0.8)\n","Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.10/dist-packages (from gym->elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.6) (2.3.5)\n","Requirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gym->elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.6) (4.1.1.post0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[default,tune]<3,>=2->finrl==0.3.6) (2023.11.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[default,tune]<3,>=2->finrl==0.3.6) (0.31.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[default,tune]<3,>=2->finrl==0.3.6) (0.13.0)\n","Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (0.1.3)\n","Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (2.11.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.0.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (6.1.1)\n","Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[default,tune]<3,>=2->finrl==0.3.6) (0.2.10)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.6) (2.21)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (1.61.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.3.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.8.3)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.1.2)\n","Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.4.1->cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (0.1.7.post0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.7.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.2.2)\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","Shape of DataFrame:  (73977, 8)\n","Successfully added technical indicators\n","[*********************100%%**********************]  1 of 1 completed\n","Shape of DataFrame:  (2517, 8)\n","Successfully added vix\n","Successfully added turbulence index\n","36511\n","36482\n","Stock Dimension: 29, State Space: 291\n","<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n","{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n","Using cpu device\n","Logging to results/a2c\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 98         |\n","|    iterations         | 100        |\n","|    time_elapsed       | 5          |\n","|    total_timesteps    | 500        |\n","| train/                |            |\n","|    entropy_loss       | -41.3      |\n","|    explained_variance | -0.107     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 99         |\n","|    policy_loss        | 135        |\n","|    reward             | 0.13997817 |\n","|    std                | 1.01       |\n","|    value_loss         | 12.3       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 117        |\n","|    iterations         | 200        |\n","|    time_elapsed       | 8          |\n","|    total_timesteps    | 1000       |\n","| train/                |            |\n","|    entropy_loss       | -41.4      |\n","|    explained_variance | 0.0103     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 199        |\n","|    policy_loss        | 86.2       |\n","|    reward             | 0.86935204 |\n","|    std                | 1.01       |\n","|    value_loss         | 6.28       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 125       |\n","|    iterations         | 300       |\n","|    time_elapsed       | 11        |\n","|    total_timesteps    | 1500      |\n","| train/                |           |\n","|    entropy_loss       | -41.4     |\n","|    explained_variance | -0.0294   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 299       |\n","|    policy_loss        | 25.9      |\n","|    reward             | 0.6987618 |\n","|    std                | 1.01      |\n","|    value_loss         | 0.707     |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 119       |\n","|    iterations         | 400       |\n","|    time_elapsed       | 16        |\n","|    total_timesteps    | 2000      |\n","| train/                |           |\n","|    entropy_loss       | -41.5     |\n","|    explained_variance | 0.0466    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 399       |\n","|    policy_loss        | -203      |\n","|    reward             | 1.1150846 |\n","|    std                | 1.01      |\n","|    value_loss         | 24.6      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 111       |\n","|    iterations         | 500       |\n","|    time_elapsed       | 22        |\n","|    total_timesteps    | 2500      |\n","| train/                |           |\n","|    entropy_loss       | -41.4     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 499       |\n","|    policy_loss        | 91.6      |\n","|    reward             | 0.6910957 |\n","|    std                | 1.01      |\n","|    value_loss         | 4.84      |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 115         |\n","|    iterations         | 600         |\n","|    time_elapsed       | 26          |\n","|    total_timesteps    | 3000        |\n","| train/                |             |\n","|    entropy_loss       | -41.5       |\n","|    explained_variance | -0.0549     |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 599         |\n","|    policy_loss        | 112         |\n","|    reward             | -0.84497905 |\n","|    std                | 1.01        |\n","|    value_loss         | 7.7         |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 118       |\n","|    iterations         | 700       |\n","|    time_elapsed       | 29        |\n","|    total_timesteps    | 3500      |\n","| train/                |           |\n","|    entropy_loss       | -41.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 699       |\n","|    policy_loss        | -13.5     |\n","|    reward             | 1.2633303 |\n","|    std                | 1.01      |\n","|    value_loss         | 0.99      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 119        |\n","|    iterations         | 800        |\n","|    time_elapsed       | 33         |\n","|    total_timesteps    | 4000       |\n","| train/                |            |\n","|    entropy_loss       | -41.5      |\n","|    explained_variance | 0.0585     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 799        |\n","|    policy_loss        | -1.41      |\n","|    reward             | -0.4019015 |\n","|    std                | 1.01       |\n","|    value_loss         | 0.362      |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 114        |\n","|    iterations         | 900        |\n","|    time_elapsed       | 39         |\n","|    total_timesteps    | 4500       |\n","| train/                |            |\n","|    entropy_loss       | -41.5      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 899        |\n","|    policy_loss        | 40         |\n","|    reward             | -0.8852674 |\n","|    std                | 1.01       |\n","|    value_loss         | 2.24       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 115       |\n","|    iterations         | 1000      |\n","|    time_elapsed       | 43        |\n","|    total_timesteps    | 5000      |\n","| train/                |           |\n","|    entropy_loss       | -41.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 999       |\n","|    policy_loss        | 50.5      |\n","|    reward             | 0.2953758 |\n","|    std                | 1.01      |\n","|    value_loss         | 1.55      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 116       |\n","|    iterations         | 1100      |\n","|    time_elapsed       | 47        |\n","|    total_timesteps    | 5500      |\n","| train/                |           |\n","|    entropy_loss       | -41.6     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1099      |\n","|    policy_loss        | 142       |\n","|    reward             | 1.1905962 |\n","|    std                | 1.02      |\n","|    value_loss         | 10.6      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 118        |\n","|    iterations         | 1200       |\n","|    time_elapsed       | 50         |\n","|    total_timesteps    | 6000       |\n","| train/                |            |\n","|    entropy_loss       | -41.6      |\n","|    explained_variance | -0.0376    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1199       |\n","|    policy_loss        | -101       |\n","|    reward             | 0.37573585 |\n","|    std                | 1.02       |\n","|    value_loss         | 6.17       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 115        |\n","|    iterations         | 1300       |\n","|    time_elapsed       | 56         |\n","|    total_timesteps    | 6500       |\n","| train/                |            |\n","|    entropy_loss       | -41.6      |\n","|    explained_variance | 0.138      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1299       |\n","|    policy_loss        | 68.7       |\n","|    reward             | 0.86194026 |\n","|    std                | 1.02       |\n","|    value_loss         | 2.88       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 110        |\n","|    iterations         | 1400       |\n","|    time_elapsed       | 63         |\n","|    total_timesteps    | 7000       |\n","| train/                |            |\n","|    entropy_loss       | -41.7      |\n","|    explained_variance | 0.0693     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1399       |\n","|    policy_loss        | 31.4       |\n","|    reward             | 0.36115906 |\n","|    std                | 1.02       |\n","|    value_loss         | 2.09       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 109        |\n","|    iterations         | 1500       |\n","|    time_elapsed       | 68         |\n","|    total_timesteps    | 7500       |\n","| train/                |            |\n","|    entropy_loss       | -41.7      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1499       |\n","|    policy_loss        | 66.9       |\n","|    reward             | 0.31654862 |\n","|    std                | 1.02       |\n","|    value_loss         | 3.85       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 111       |\n","|    iterations         | 1600      |\n","|    time_elapsed       | 71        |\n","|    total_timesteps    | 8000      |\n","| train/                |           |\n","|    entropy_loss       | -41.8     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1599      |\n","|    policy_loss        | -83.9     |\n","|    reward             | -2.415426 |\n","|    std                | 1.02      |\n","|    value_loss         | 5.04      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 111        |\n","|    iterations         | 1700       |\n","|    time_elapsed       | 76         |\n","|    total_timesteps    | 8500       |\n","| train/                |            |\n","|    entropy_loss       | -41.8      |\n","|    explained_variance | -0.203     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1699       |\n","|    policy_loss        | -35.1      |\n","|    reward             | 0.07564574 |\n","|    std                | 1.02       |\n","|    value_loss         | 2.75       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 109        |\n","|    iterations         | 1800       |\n","|    time_elapsed       | 82         |\n","|    total_timesteps    | 9000       |\n","| train/                |            |\n","|    entropy_loss       | -41.9      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1799       |\n","|    policy_loss        | -15        |\n","|    reward             | -1.2790308 |\n","|    std                | 1.03       |\n","|    value_loss         | 0.778      |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 110        |\n","|    iterations         | 1900       |\n","|    time_elapsed       | 85         |\n","|    total_timesteps    | 9500       |\n","| train/                |            |\n","|    entropy_loss       | -42        |\n","|    explained_variance | 0.367      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1899       |\n","|    policy_loss        | 74.4       |\n","|    reward             | -0.3657235 |\n","|    std                | 1.03       |\n","|    value_loss         | 5.36       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 112        |\n","|    iterations         | 2000       |\n","|    time_elapsed       | 89         |\n","|    total_timesteps    | 10000      |\n","| train/                |            |\n","|    entropy_loss       | -41.9      |\n","|    explained_variance | 0.049      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1999       |\n","|    policy_loss        | 96.2       |\n","|    reward             | 0.19548324 |\n","|    std                | 1.03       |\n","|    value_loss         | 6.07       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 113         |\n","|    iterations         | 2100        |\n","|    time_elapsed       | 92          |\n","|    total_timesteps    | 10500       |\n","| train/                |             |\n","|    entropy_loss       | -42         |\n","|    explained_variance | -0.0787     |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 2099        |\n","|    policy_loss        | 68.7        |\n","|    reward             | -0.25752234 |\n","|    std                | 1.03        |\n","|    value_loss         | 3.3         |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 111        |\n","|    iterations         | 2200       |\n","|    time_elapsed       | 98         |\n","|    total_timesteps    | 11000      |\n","| train/                |            |\n","|    entropy_loss       | -42        |\n","|    explained_variance | 0.00797    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2199       |\n","|    policy_loss        | -55.8      |\n","|    reward             | -1.0648159 |\n","|    std                | 1.03       |\n","|    value_loss         | 1.77       |\n","--------------------------------------\n","day: 1258, episode: 10\n","begin_total_asset: 1000000.00\n","end_total_asset: 2281800.43\n","total_reward: 1281800.43\n","total_cost: 46885.10\n","total_trades: 24249\n","Sharpe: 1.226\n","=================================\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 111        |\n","|    iterations         | 2300       |\n","|    time_elapsed       | 102        |\n","|    total_timesteps    | 11500      |\n","| train/                |            |\n","|    entropy_loss       | -42.1      |\n","|    explained_variance | 1.44e-05   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2299       |\n","|    policy_loss        | -79.4      |\n","|    reward             | 0.23340449 |\n","|    std                | 1.03       |\n","|    value_loss         | 3.29       |\n","--------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 112      |\n","|    iterations         | 2400     |\n","|    time_elapsed       | 106      |\n","|    total_timesteps    | 12000    |\n","| train/                |          |\n","|    entropy_loss       | -42.1    |\n","|    explained_variance | 0.152    |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 2399     |\n","|    policy_loss        | -295     |\n","|    reward             | 0.056606 |\n","|    std                | 1.03     |\n","|    value_loss         | 49.4     |\n","------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 113        |\n","|    iterations         | 2500       |\n","|    time_elapsed       | 109        |\n","|    total_timesteps    | 12500      |\n","| train/                |            |\n","|    entropy_loss       | -42.1      |\n","|    explained_variance | 5.96e-08   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2499       |\n","|    policy_loss        | 40.9       |\n","|    reward             | -1.2590486 |\n","|    std                | 1.03       |\n","|    value_loss         | 1.66       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 113       |\n","|    iterations         | 2600      |\n","|    time_elapsed       | 114       |\n","|    total_timesteps    | 13000     |\n","| train/                |           |\n","|    entropy_loss       | -42.2     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2599      |\n","|    policy_loss        | 13.7      |\n","|    reward             | 1.5029377 |\n","|    std                | 1.04      |\n","|    value_loss         | 0.397     |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 112         |\n","|    iterations         | 2700        |\n","|    time_elapsed       | 120         |\n","|    total_timesteps    | 13500       |\n","| train/                |             |\n","|    entropy_loss       | -42.2       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 2699        |\n","|    policy_loss        | 99.2        |\n","|    reward             | -0.21377215 |\n","|    std                | 1.04        |\n","|    value_loss         | 6.38        |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 113        |\n","|    iterations         | 2800       |\n","|    time_elapsed       | 123        |\n","|    total_timesteps    | 14000      |\n","| train/                |            |\n","|    entropy_loss       | -42.3      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2799       |\n","|    policy_loss        | -51.6      |\n","|    reward             | 0.12148675 |\n","|    std                | 1.04       |\n","|    value_loss         | 3.2        |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 114        |\n","|    iterations         | 2900       |\n","|    time_elapsed       | 127        |\n","|    total_timesteps    | 14500      |\n","| train/                |            |\n","|    entropy_loss       | -42.3      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2899       |\n","|    policy_loss        | 94.2       |\n","|    reward             | -0.9615664 |\n","|    std                | 1.04       |\n","|    value_loss         | 6.69       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 114        |\n","|    iterations         | 3000       |\n","|    time_elapsed       | 131        |\n","|    total_timesteps    | 15000      |\n","| train/                |            |\n","|    entropy_loss       | -42.3      |\n","|    explained_variance | 1.19e-07   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2999       |\n","|    policy_loss        | 151        |\n","|    reward             | -0.8266926 |\n","|    std                | 1.04       |\n","|    value_loss         | 15.9       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 112         |\n","|    iterations         | 3100        |\n","|    time_elapsed       | 137         |\n","|    total_timesteps    | 15500       |\n","| train/                |             |\n","|    entropy_loss       | -42.3       |\n","|    explained_variance | -0.0498     |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 3099        |\n","|    policy_loss        | -19.1       |\n","|    reward             | -0.12913467 |\n","|    std                | 1.04        |\n","|    value_loss         | 0.841       |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 113       |\n","|    iterations         | 3200      |\n","|    time_elapsed       | 141       |\n","|    total_timesteps    | 16000     |\n","| train/                |           |\n","|    entropy_loss       | -42.3     |\n","|    explained_variance | -0.0717   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3199      |\n","|    policy_loss        | 57.1      |\n","|    reward             | 1.5637629 |\n","|    std                | 1.04      |\n","|    value_loss         | 2.56      |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 114         |\n","|    iterations         | 3300        |\n","|    time_elapsed       | 144         |\n","|    total_timesteps    | 16500       |\n","| train/                |             |\n","|    entropy_loss       | -42.4       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 3299        |\n","|    policy_loss        | 59.8        |\n","|    reward             | -0.18507779 |\n","|    std                | 1.04        |\n","|    value_loss         | 2.35        |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 114       |\n","|    iterations         | 3400      |\n","|    time_elapsed       | 147       |\n","|    total_timesteps    | 17000     |\n","| train/                |           |\n","|    entropy_loss       | -42.4     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3399      |\n","|    policy_loss        | -3.78     |\n","|    reward             | 0.3818839 |\n","|    std                | 1.04      |\n","|    value_loss         | 2.91      |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 114         |\n","|    iterations         | 3500        |\n","|    time_elapsed       | 153         |\n","|    total_timesteps    | 17500       |\n","| train/                |             |\n","|    entropy_loss       | -42.4       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 3499        |\n","|    policy_loss        | 19.9        |\n","|    reward             | 0.054894526 |\n","|    std                | 1.05        |\n","|    value_loss         | 0.735       |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 113        |\n","|    iterations         | 3600       |\n","|    time_elapsed       | 158        |\n","|    total_timesteps    | 18000      |\n","| train/                |            |\n","|    entropy_loss       | -42.4      |\n","|    explained_variance | -0.00209   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3599       |\n","|    policy_loss        | 23         |\n","|    reward             | 0.24379522 |\n","|    std                | 1.04       |\n","|    value_loss         | 0.392      |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 114         |\n","|    iterations         | 3700        |\n","|    time_elapsed       | 161         |\n","|    total_timesteps    | 18500       |\n","| train/                |             |\n","|    entropy_loss       | -42.4       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 3699        |\n","|    policy_loss        | -130        |\n","|    reward             | -0.45851076 |\n","|    std                | 1.05        |\n","|    value_loss         | 16.7        |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 115       |\n","|    iterations         | 3800      |\n","|    time_elapsed       | 164       |\n","|    total_timesteps    | 19000     |\n","| train/                |           |\n","|    entropy_loss       | -42.5     |\n","|    explained_variance | 0.0131    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3799      |\n","|    policy_loss        | 14.5      |\n","|    reward             | 1.3420062 |\n","|    std                | 1.05      |\n","|    value_loss         | 1.54      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 114        |\n","|    iterations         | 3900       |\n","|    time_elapsed       | 169        |\n","|    total_timesteps    | 19500      |\n","| train/                |            |\n","|    entropy_loss       | -42.4      |\n","|    explained_variance | 5.96e-08   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3899       |\n","|    policy_loss        | -35.7      |\n","|    reward             | -1.6385577 |\n","|    std                | 1.05       |\n","|    value_loss         | 0.828      |\n","--------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 113      |\n","|    iterations         | 4000     |\n","|    time_elapsed       | 175      |\n","|    total_timesteps    | 20000    |\n","| train/                |          |\n","|    entropy_loss       | -42.5    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 3999     |\n","|    policy_loss        | 37.1     |\n","|    reward             | 1.672772 |\n","|    std                | 1.05     |\n","|    value_loss         | 0.872    |\n","------------------------------------\n","----------------------------------------\n","| time/                 |              |\n","|    fps                | 114          |\n","|    iterations         | 4100         |\n","|    time_elapsed       | 178          |\n","|    total_timesteps    | 20500        |\n","| train/                |              |\n","|    entropy_loss       | -42.4        |\n","|    explained_variance | 0            |\n","|    learning_rate      | 0.0007       |\n","|    n_updates          | 4099         |\n","|    policy_loss        | 85.1         |\n","|    reward             | 0.0041997605 |\n","|    std                | 1.05         |\n","|    value_loss         | 4.59         |\n","----------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 115        |\n","|    iterations         | 4200       |\n","|    time_elapsed       | 182        |\n","|    total_timesteps    | 21000      |\n","| train/                |            |\n","|    entropy_loss       | -42.4      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 4199       |\n","|    policy_loss        | -138       |\n","|    reward             | 0.15116958 |\n","|    std                | 1.05       |\n","|    value_loss         | 12.2       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 115         |\n","|    iterations         | 4300        |\n","|    time_elapsed       | 185         |\n","|    total_timesteps    | 21500       |\n","| train/                |             |\n","|    entropy_loss       | -42.4       |\n","|    explained_variance | -0.37       |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 4299        |\n","|    policy_loss        | 77.3        |\n","|    reward             | -0.04659188 |\n","|    std                | 1.05        |\n","|    value_loss         | 3.96        |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 114       |\n","|    iterations         | 4400      |\n","|    time_elapsed       | 191       |\n","|    total_timesteps    | 22000     |\n","| train/                |           |\n","|    entropy_loss       | -42.5     |\n","|    explained_variance | 0.206     |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 4399      |\n","|    policy_loss        | 18.3      |\n","|    reward             | 0.3652242 |\n","|    std                | 1.05      |\n","|    value_loss         | 1.12      |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 114         |\n","|    iterations         | 4500        |\n","|    time_elapsed       | 195         |\n","|    total_timesteps    | 22500       |\n","| train/                |             |\n","|    entropy_loss       | -42.5       |\n","|    explained_variance | -1.19e-07   |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 4499        |\n","|    policy_loss        | -30.6       |\n","|    reward             | -0.43582875 |\n","|    std                | 1.05        |\n","|    value_loss         | 0.54        |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 115       |\n","|    iterations         | 4600      |\n","|    time_elapsed       | 199       |\n","|    total_timesteps    | 23000     |\n","| train/                |           |\n","|    entropy_loss       | -42.5     |\n","|    explained_variance | 0.0341    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 4599      |\n","|    policy_loss        | -0.0307   |\n","|    reward             | 1.1098517 |\n","|    std                | 1.05      |\n","|    value_loss         | 0.13      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 115        |\n","|    iterations         | 4700       |\n","|    time_elapsed       | 202        |\n","|    total_timesteps    | 23500      |\n","| train/                |            |\n","|    entropy_loss       | -42.6      |\n","|    explained_variance | 0.105      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 4699       |\n","|    policy_loss        | -64        |\n","|    reward             | 0.87210023 |\n","|    std                | 1.05       |\n","|    value_loss         | 2.47       |\n","--------------------------------------\n","day: 1258, episode: 20\n","begin_total_asset: 1000000.00\n","end_total_asset: 1991894.54\n","total_reward: 991894.54\n","total_cost: 56843.54\n","total_trades: 25036\n","Sharpe: 1.070\n","=================================\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 115        |\n","|    iterations         | 4800       |\n","|    time_elapsed       | 207        |\n","|    total_timesteps    | 24000      |\n","| train/                |            |\n","|    entropy_loss       | -42.6      |\n","|    explained_variance | 0.0796     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 4799       |\n","|    policy_loss        | 54.2       |\n","|    reward             | -0.0786307 |\n","|    std                | 1.05       |\n","|    value_loss         | 2.4        |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 114       |\n","|    iterations         | 4900      |\n","|    time_elapsed       | 213       |\n","|    total_timesteps    | 24500     |\n","| train/                |           |\n","|    entropy_loss       | -42.5     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 4899      |\n","|    policy_loss        | 13.7      |\n","|    reward             | 1.1786447 |\n","|    std                | 1.05      |\n","|    value_loss         | 0.229     |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 115       |\n","|    iterations         | 5000      |\n","|    time_elapsed       | 216       |\n","|    total_timesteps    | 25000     |\n","| train/                |           |\n","|    entropy_loss       | -42.4     |\n","|    explained_variance | 1.79e-07  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 4999      |\n","|    policy_loss        | -3.38     |\n","|    reward             | 1.2828996 |\n","|    std                | 1.05      |\n","|    value_loss         | 0.378     |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 115        |\n","|    iterations         | 5100       |\n","|    time_elapsed       | 219        |\n","|    total_timesteps    | 25500      |\n","| train/                |            |\n","|    entropy_loss       | -42.4      |\n","|    explained_variance | -0.0147    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 5099       |\n","|    policy_loss        | 37.7       |\n","|    reward             | -3.7904503 |\n","|    std                | 1.05       |\n","|    value_loss         | 1          |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 115       |\n","|    iterations         | 5200      |\n","|    time_elapsed       | 224       |\n","|    total_timesteps    | 26000     |\n","| train/                |           |\n","|    entropy_loss       | -42.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 5199      |\n","|    policy_loss        | 33.6      |\n","|    reward             | 0.6046089 |\n","|    std                | 1.05      |\n","|    value_loss         | 0.797     |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 115       |\n","|    iterations         | 5300      |\n","|    time_elapsed       | 230       |\n","|    total_timesteps    | 26500     |\n","| train/                |           |\n","|    entropy_loss       | -42.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 5299      |\n","|    policy_loss        | 27.1      |\n","|    reward             | 1.2099369 |\n","|    std                | 1.05      |\n","|    value_loss         | 0.642     |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 115        |\n","|    iterations         | 5400       |\n","|    time_elapsed       | 233        |\n","|    total_timesteps    | 27000      |\n","| train/                |            |\n","|    entropy_loss       | -42.6      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 5399       |\n","|    policy_loss        | 20.8       |\n","|    reward             | -1.1065935 |\n","|    std                | 1.05       |\n","|    value_loss         | 2.2        |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 115        |\n","|    iterations         | 5500       |\n","|    time_elapsed       | 237        |\n","|    total_timesteps    | 27500      |\n","| train/                |            |\n","|    entropy_loss       | -42.6      |\n","|    explained_variance | -12.9      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 5499       |\n","|    policy_loss        | 53.2       |\n","|    reward             | -1.7299821 |\n","|    std                | 1.05       |\n","|    value_loss         | 2.32       |\n","--------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 116      |\n","|    iterations         | 5600     |\n","|    time_elapsed       | 241      |\n","|    total_timesteps    | 28000    |\n","| train/                |          |\n","|    entropy_loss       | -42.6    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 5599     |\n","|    policy_loss        | 2.08     |\n","|    reward             | 0.985435 |\n","|    std                | 1.05     |\n","|    value_loss         | 0.829    |\n","------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 115        |\n","|    iterations         | 5700       |\n","|    time_elapsed       | 246        |\n","|    total_timesteps    | 28500      |\n","| train/                |            |\n","|    entropy_loss       | -42.6      |\n","|    explained_variance | -0.000924  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 5699       |\n","|    policy_loss        | 15.1       |\n","|    reward             | -0.6566617 |\n","|    std                | 1.05       |\n","|    value_loss         | 0.883      |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 115        |\n","|    iterations         | 5800       |\n","|    time_elapsed       | 251        |\n","|    total_timesteps    | 29000      |\n","| train/                |            |\n","|    entropy_loss       | -42.6      |\n","|    explained_variance | -0.246     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 5799       |\n","|    policy_loss        | 35.7       |\n","|    reward             | 0.23236124 |\n","|    std                | 1.05       |\n","|    value_loss         | 1.03       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 115       |\n","|    iterations         | 5900      |\n","|    time_elapsed       | 254       |\n","|    total_timesteps    | 29500     |\n","| train/                |           |\n","|    entropy_loss       | -42.6     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 5899      |\n","|    policy_loss        | 41.9      |\n","|    reward             | 0.5903312 |\n","|    std                | 1.05      |\n","|    value_loss         | 1.26      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 116        |\n","|    iterations         | 6000       |\n","|    time_elapsed       | 258        |\n","|    total_timesteps    | 30000      |\n","| train/                |            |\n","|    entropy_loss       | -42.7      |\n","|    explained_variance | 0.00838    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 5999       |\n","|    policy_loss        | 103        |\n","|    reward             | 0.93560237 |\n","|    std                | 1.05       |\n","|    value_loss         | 7.43       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 115         |\n","|    iterations         | 6100        |\n","|    time_elapsed       | 263         |\n","|    total_timesteps    | 30500       |\n","| train/                |             |\n","|    entropy_loss       | -42.7       |\n","|    explained_variance | 1.79e-07    |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 6099        |\n","|    policy_loss        | 217         |\n","|    reward             | -0.32187203 |\n","|    std                | 1.06        |\n","|    value_loss         | 27.6        |\n","---------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 115      |\n","|    iterations         | 6200     |\n","|    time_elapsed       | 268      |\n","|    total_timesteps    | 31000    |\n","| train/                |          |\n","|    entropy_loss       | -42.7    |\n","|    explained_variance | 0.00429  |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 6199     |\n","|    policy_loss        | -72.8    |\n","|    reward             | 4.225057 |\n","|    std                | 1.06     |\n","|    value_loss         | 3.89     |\n","------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 115         |\n","|    iterations         | 6300        |\n","|    time_elapsed       | 271         |\n","|    total_timesteps    | 31500       |\n","| train/                |             |\n","|    entropy_loss       | -42.7       |\n","|    explained_variance | -0.484      |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 6299        |\n","|    policy_loss        | 4.45        |\n","|    reward             | -0.17833158 |\n","|    std                | 1.06        |\n","|    value_loss         | 0.0442      |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 116       |\n","|    iterations         | 6400      |\n","|    time_elapsed       | 275       |\n","|    total_timesteps    | 32000     |\n","| train/                |           |\n","|    entropy_loss       | -42.8     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 6399      |\n","|    policy_loss        | -144      |\n","|    reward             | 2.3713682 |\n","|    std                | 1.06      |\n","|    value_loss         | 10.8      |\n","-------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 116      |\n","|    iterations         | 6500     |\n","|    time_elapsed       | 279      |\n","|    total_timesteps    | 32500    |\n","| train/                |          |\n","|    entropy_loss       | -42.7    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 6499     |\n","|    policy_loss        | -41.5    |\n","|    reward             | 0.427139 |\n","|    std                | 1.06     |\n","|    value_loss         | 1.59     |\n","------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 115        |\n","|    iterations         | 6600       |\n","|    time_elapsed       | 285        |\n","|    total_timesteps    | 33000      |\n","| train/                |            |\n","|    entropy_loss       | -42.8      |\n","|    explained_variance | -0.0745    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 6599       |\n","|    policy_loss        | 23.9       |\n","|    reward             | -2.1448913 |\n","|    std                | 1.06       |\n","|    value_loss         | 1.51       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 115         |\n","|    iterations         | 6700        |\n","|    time_elapsed       | 289         |\n","|    total_timesteps    | 33500       |\n","| train/                |             |\n","|    entropy_loss       | -42.8       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 6699        |\n","|    policy_loss        | -161        |\n","|    reward             | -0.43841624 |\n","|    std                | 1.06        |\n","|    value_loss         | 20.8        |\n","---------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 116         |\n","|    iterations         | 6800        |\n","|    time_elapsed       | 292         |\n","|    total_timesteps    | 34000       |\n","| train/                |             |\n","|    entropy_loss       | -42.9       |\n","|    explained_variance | -0.35       |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 6799        |\n","|    policy_loss        | -341        |\n","|    reward             | 0.040499423 |\n","|    std                | 1.06        |\n","|    value_loss         | 116         |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 116       |\n","|    iterations         | 6900      |\n","|    time_elapsed       | 296       |\n","|    total_timesteps    | 34500     |\n","| train/                |           |\n","|    entropy_loss       | -42.9     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 6899      |\n","|    policy_loss        | -7.77     |\n","|    reward             | 2.0002    |\n","|    std                | 1.06      |\n","|    value_loss         | 0.059     |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 115        |\n","|    iterations         | 7000       |\n","|    time_elapsed       | 301        |\n","|    total_timesteps    | 35000      |\n","| train/                |            |\n","|    entropy_loss       | -43        |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 6999       |\n","|    policy_loss        | -31        |\n","|    reward             | 0.15492499 |\n","|    std                | 1.07       |\n","|    value_loss         | 0.935      |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 115       |\n","|    iterations         | 7100      |\n","|    time_elapsed       | 306       |\n","|    total_timesteps    | 35500     |\n","| train/                |           |\n","|    entropy_loss       | -43       |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 7099      |\n","|    policy_loss        | 92.4      |\n","|    reward             | 0.6680443 |\n","|    std                | 1.07      |\n","|    value_loss         | 4.94      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 116       |\n","|    iterations         | 7200      |\n","|    time_elapsed       | 309       |\n","|    total_timesteps    | 36000     |\n","| train/                |           |\n","|    entropy_loss       | -43       |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 7199      |\n","|    policy_loss        | -83.5     |\n","|    reward             | 1.3185625 |\n","|    std                | 1.07      |\n","|    value_loss         | 7.37      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 116        |\n","|    iterations         | 7300       |\n","|    time_elapsed       | 313        |\n","|    total_timesteps    | 36500      |\n","| train/                |            |\n","|    entropy_loss       | -43.1      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 7299       |\n","|    policy_loss        | -4.67      |\n","|    reward             | -2.0944757 |\n","|    std                | 1.07       |\n","|    value_loss         | 0.944      |\n","--------------------------------------\n","day: 1258, episode: 30\n","begin_total_asset: 1000000.00\n","end_total_asset: 2397298.00\n","total_reward: 1397298.00\n","total_cost: 27825.52\n","total_trades: 25432\n","Sharpe: 1.404\n","=================================\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 116        |\n","|    iterations         | 7400       |\n","|    time_elapsed       | 317        |\n","|    total_timesteps    | 37000      |\n","| train/                |            |\n","|    entropy_loss       | -43.1      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 7399       |\n","|    policy_loss        | 14.1       |\n","|    reward             | -1.9981198 |\n","|    std                | 1.07       |\n","|    value_loss         | 0.35       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 115       |\n","|    iterations         | 7500      |\n","|    time_elapsed       | 323       |\n","|    total_timesteps    | 37500     |\n","| train/                |           |\n","|    entropy_loss       | -43.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 7499      |\n","|    policy_loss        | 25.6      |\n","|    reward             | -1.570362 |\n","|    std                | 1.07      |\n","|    value_loss         | 1.86      |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 116         |\n","|    iterations         | 7600        |\n","|    time_elapsed       | 326         |\n","|    total_timesteps    | 38000       |\n","| train/                |             |\n","|    entropy_loss       | -43.1       |\n","|    explained_variance | 0.168       |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 7599        |\n","|    policy_loss        | 38.4        |\n","|    reward             | 0.099220365 |\n","|    std                | 1.07        |\n","|    value_loss         | 0.981       |\n","---------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 116         |\n","|    iterations         | 7700        |\n","|    time_elapsed       | 330         |\n","|    total_timesteps    | 38500       |\n","| train/                |             |\n","|    entropy_loss       | -43.1       |\n","|    explained_variance | 0.00529     |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 7699        |\n","|    policy_loss        | 32.1        |\n","|    reward             | -0.35284528 |\n","|    std                | 1.07        |\n","|    value_loss         | 3.56        |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 116        |\n","|    iterations         | 7800       |\n","|    time_elapsed       | 333        |\n","|    total_timesteps    | 39000      |\n","| train/                |            |\n","|    entropy_loss       | -43.2      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 7799       |\n","|    policy_loss        | -61.9      |\n","|    reward             | -1.5152128 |\n","|    std                | 1.07       |\n","|    value_loss         | 2.81       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 116        |\n","|    iterations         | 7900       |\n","|    time_elapsed       | 339        |\n","|    total_timesteps    | 39500      |\n","| train/                |            |\n","|    entropy_loss       | -43.2      |\n","|    explained_variance | 0.0269     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 7899       |\n","|    policy_loss        | 74.9       |\n","|    reward             | 0.40260416 |\n","|    std                | 1.08       |\n","|    value_loss         | 4.25       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 116        |\n","|    iterations         | 8000       |\n","|    time_elapsed       | 344        |\n","|    total_timesteps    | 40000      |\n","| train/                |            |\n","|    entropy_loss       | -43.3      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 7999       |\n","|    policy_loss        | -69.5      |\n","|    reward             | 0.65881836 |\n","|    std                | 1.08       |\n","|    value_loss         | 3.78       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 116         |\n","|    iterations         | 8100        |\n","|    time_elapsed       | 347         |\n","|    total_timesteps    | 40500       |\n","| train/                |             |\n","|    entropy_loss       | -43.3       |\n","|    explained_variance | -0.00151    |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 8099        |\n","|    policy_loss        | 60.1        |\n","|    reward             | 0.006431039 |\n","|    std                | 1.08        |\n","|    value_loss         | 3.55        |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 116        |\n","|    iterations         | 8200       |\n","|    time_elapsed       | 351        |\n","|    total_timesteps    | 41000      |\n","| train/                |            |\n","|    entropy_loss       | -43.3      |\n","|    explained_variance | -0.318     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 8199       |\n","|    policy_loss        | 227        |\n","|    reward             | -0.2050264 |\n","|    std                | 1.08       |\n","|    value_loss         | 26.3       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 116        |\n","|    iterations         | 8300       |\n","|    time_elapsed       | 356        |\n","|    total_timesteps    | 41500      |\n","| train/                |            |\n","|    entropy_loss       | -43.3      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 8299       |\n","|    policy_loss        | 78.7       |\n","|    reward             | 0.79111844 |\n","|    std                | 1.08       |\n","|    value_loss         | 4.35       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 116       |\n","|    iterations         | 8400      |\n","|    time_elapsed       | 361       |\n","|    total_timesteps    | 42000     |\n","| train/                |           |\n","|    entropy_loss       | -43.4     |\n","|    explained_variance | 0.0445    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 8399      |\n","|    policy_loss        | -232      |\n","|    reward             | 0.9021646 |\n","|    std                | 1.08      |\n","|    value_loss         | 30.8      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 116        |\n","|    iterations         | 8500       |\n","|    time_elapsed       | 364        |\n","|    total_timesteps    | 42500      |\n","| train/                |            |\n","|    entropy_loss       | -43.4      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 8499       |\n","|    policy_loss        | 37.7       |\n","|    reward             | 0.28638598 |\n","|    std                | 1.08       |\n","|    value_loss         | 1.58       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 116         |\n","|    iterations         | 8600        |\n","|    time_elapsed       | 368         |\n","|    total_timesteps    | 43000       |\n","| train/                |             |\n","|    entropy_loss       | -43.4       |\n","|    explained_variance | 0.0269      |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 8599        |\n","|    policy_loss        | -18.8       |\n","|    reward             | -0.51932424 |\n","|    std                | 1.08        |\n","|    value_loss         | 0.735       |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 116       |\n","|    iterations         | 8700      |\n","|    time_elapsed       | 373       |\n","|    total_timesteps    | 43500     |\n","| train/                |           |\n","|    entropy_loss       | -43.4     |\n","|    explained_variance | 0.0179    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 8699      |\n","|    policy_loss        | -348      |\n","|    reward             | 2.7684042 |\n","|    std                | 1.08      |\n","|    value_loss         | 65.8      |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 116         |\n","|    iterations         | 8800        |\n","|    time_elapsed       | 378         |\n","|    total_timesteps    | 44000       |\n","| train/                |             |\n","|    entropy_loss       | -43.5       |\n","|    explained_variance | 0.0958      |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 8799        |\n","|    policy_loss        | -120        |\n","|    reward             | 0.061056517 |\n","|    std                | 1.09        |\n","|    value_loss         | 10.4        |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 116        |\n","|    iterations         | 8900       |\n","|    time_elapsed       | 382        |\n","|    total_timesteps    | 44500      |\n","| train/                |            |\n","|    entropy_loss       | -43.5      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 8899       |\n","|    policy_loss        | 48.6       |\n","|    reward             | 0.47505182 |\n","|    std                | 1.09       |\n","|    value_loss         | 1.76       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 116         |\n","|    iterations         | 9000        |\n","|    time_elapsed       | 385         |\n","|    total_timesteps    | 45000       |\n","| train/                |             |\n","|    entropy_loss       | -43.5       |\n","|    explained_variance | -1.19e-07   |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 8999        |\n","|    policy_loss        | 8.99        |\n","|    reward             | -0.12629424 |\n","|    std                | 1.09        |\n","|    value_loss         | 1.04        |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 116        |\n","|    iterations         | 9100       |\n","|    time_elapsed       | 389        |\n","|    total_timesteps    | 45500      |\n","| train/                |            |\n","|    entropy_loss       | -43.6      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 9099       |\n","|    policy_loss        | 14.4       |\n","|    reward             | 0.40217528 |\n","|    std                | 1.09       |\n","|    value_loss         | 0.427      |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 116        |\n","|    iterations         | 9200       |\n","|    time_elapsed       | 395        |\n","|    total_timesteps    | 46000      |\n","| train/                |            |\n","|    entropy_loss       | -43.7      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 9199       |\n","|    policy_loss        | -115       |\n","|    reward             | -1.5074862 |\n","|    std                | 1.09       |\n","|    value_loss         | 17.2       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 116         |\n","|    iterations         | 9300        |\n","|    time_elapsed       | 399         |\n","|    total_timesteps    | 46500       |\n","| train/                |             |\n","|    entropy_loss       | -43.7       |\n","|    explained_variance | -1.19e-07   |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 9299        |\n","|    policy_loss        | 10.3        |\n","|    reward             | -0.20780908 |\n","|    std                | 1.1         |\n","|    value_loss         | 0.16        |\n","---------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 116         |\n","|    iterations         | 9400        |\n","|    time_elapsed       | 402         |\n","|    total_timesteps    | 47000       |\n","| train/                |             |\n","|    entropy_loss       | -43.7       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 9399        |\n","|    policy_loss        | 54.9        |\n","|    reward             | -0.27467743 |\n","|    std                | 1.1         |\n","|    value_loss         | 2.26        |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 116        |\n","|    iterations         | 9500       |\n","|    time_elapsed       | 407        |\n","|    total_timesteps    | 47500      |\n","| train/                |            |\n","|    entropy_loss       | -43.8      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 9499       |\n","|    policy_loss        | -8.84      |\n","|    reward             | 0.21628338 |\n","|    std                | 1.1        |\n","|    value_loss         | 0.556      |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 115        |\n","|    iterations         | 9600       |\n","|    time_elapsed       | 415        |\n","|    total_timesteps    | 48000      |\n","| train/                |            |\n","|    entropy_loss       | -43.8      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 9599       |\n","|    policy_loss        | -9.21      |\n","|    reward             | -0.9472296 |\n","|    std                | 1.1        |\n","|    value_loss         | 0.232      |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 115         |\n","|    iterations         | 9700        |\n","|    time_elapsed       | 420         |\n","|    total_timesteps    | 48500       |\n","| train/                |             |\n","|    entropy_loss       | -43.9       |\n","|    explained_variance | 0.0906      |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 9699        |\n","|    policy_loss        | -139        |\n","|    reward             | -0.80950147 |\n","|    std                | 1.1         |\n","|    value_loss         | 9.64        |\n","---------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 115         |\n","|    iterations         | 9800        |\n","|    time_elapsed       | 424         |\n","|    total_timesteps    | 49000       |\n","| train/                |             |\n","|    entropy_loss       | -43.9       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 9799        |\n","|    policy_loss        | 24.6        |\n","|    reward             | 0.052759796 |\n","|    std                | 1.1         |\n","|    value_loss         | 1.54        |\n","---------------------------------------\n","day: 1258, episode: 40\n","begin_total_asset: 1000000.00\n","end_total_asset: 2117168.50\n","total_reward: 1117168.50\n","total_cost: 9061.45\n","total_trades: 21243\n","Sharpe: 1.100\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 115       |\n","|    iterations         | 9900      |\n","|    time_elapsed       | 427       |\n","|    total_timesteps    | 49500     |\n","| train/                |           |\n","|    entropy_loss       | -43.9     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 9899      |\n","|    policy_loss        | -65.9     |\n","|    reward             | 0.7917442 |\n","|    std                | 1.1       |\n","|    value_loss         | 2.66      |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 115         |\n","|    iterations         | 10000       |\n","|    time_elapsed       | 431         |\n","|    total_timesteps    | 50000       |\n","| train/                |             |\n","|    entropy_loss       | -43.9       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 9999        |\n","|    policy_loss        | -31.8       |\n","|    reward             | 0.040202517 |\n","|    std                | 1.1         |\n","|    value_loss         | 0.725       |\n","---------------------------------------\n","{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n","Using cpu device\n","Logging to results/ddpg\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 4          |\n","|    fps             | 30         |\n","|    time_elapsed    | 166        |\n","|    total_timesteps | 5036       |\n","| train/             |            |\n","|    actor_loss      | 7.04       |\n","|    critic_loss     | 766        |\n","|    learning_rate   | 0.001      |\n","|    n_updates       | 3777       |\n","|    reward          | -1.2303032 |\n","-----------------------------------\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 8          |\n","|    fps             | 25         |\n","|    time_elapsed    | 388        |\n","|    total_timesteps | 10072      |\n","| train/             |            |\n","|    actor_loss      | 3.38       |\n","|    critic_loss     | 4.55       |\n","|    learning_rate   | 0.001      |\n","|    n_updates       | 8813       |\n","|    reward          | -1.2303032 |\n","-----------------------------------\n","day: 1258, episode: 50\n","begin_total_asset: 1000000.00\n","end_total_asset: 2326458.37\n","total_reward: 1326458.37\n","total_cost: 998.99\n","total_trades: 25149\n","Sharpe: 1.432\n","=================================\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 12         |\n","|    fps             | 24         |\n","|    time_elapsed    | 607        |\n","|    total_timesteps | 15108      |\n","| train/             |            |\n","|    actor_loss      | 0.229      |\n","|    critic_loss     | 2.03       |\n","|    learning_rate   | 0.001      |\n","|    n_updates       | 13849      |\n","|    reward          | -1.2303032 |\n","-----------------------------------\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 16         |\n","|    fps             | 24         |\n","|    time_elapsed    | 833        |\n","|    total_timesteps | 20144      |\n","| train/             |            |\n","|    actor_loss      | -2.23      |\n","|    critic_loss     | 0.306      |\n","|    learning_rate   | 0.001      |\n","|    n_updates       | 18885      |\n","|    reward          | -1.2303032 |\n","-----------------------------------\n","day: 1258, episode: 60\n","begin_total_asset: 1000000.00\n","end_total_asset: 2326458.37\n","total_reward: 1326458.37\n","total_cost: 998.99\n","total_trades: 25149\n","Sharpe: 1.432\n","=================================\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 20         |\n","|    fps             | 23         |\n","|    time_elapsed    | 1061       |\n","|    total_timesteps | 25180      |\n","| train/             |            |\n","|    actor_loss      | -3.79      |\n","|    critic_loss     | 0.293      |\n","|    learning_rate   | 0.001      |\n","|    n_updates       | 23921      |\n","|    reward          | -1.2303032 |\n","-----------------------------------\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 24         |\n","|    fps             | 23         |\n","|    time_elapsed    | 1287       |\n","|    total_timesteps | 30216      |\n","| train/             |            |\n","|    actor_loss      | -5.27      |\n","|    critic_loss     | 0.142      |\n","|    learning_rate   | 0.001      |\n","|    n_updates       | 28957      |\n","|    reward          | -1.2303032 |\n","-----------------------------------\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 28         |\n","|    fps             | 23         |\n","|    time_elapsed    | 1520       |\n","|    total_timesteps | 35252      |\n","| train/             |            |\n","|    actor_loss      | -6.1       |\n","|    critic_loss     | 0.19       |\n","|    learning_rate   | 0.001      |\n","|    n_updates       | 33993      |\n","|    reward          | -1.2303032 |\n","-----------------------------------\n","day: 1258, episode: 70\n","begin_total_asset: 1000000.00\n","end_total_asset: 2326458.37\n","total_reward: 1326458.37\n","total_cost: 998.99\n","total_trades: 25149\n","Sharpe: 1.432\n","=================================\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 32         |\n","|    fps             | 22         |\n","|    time_elapsed    | 1753       |\n","|    total_timesteps | 40288      |\n","| train/             |            |\n","|    actor_loss      | -6.92      |\n","|    critic_loss     | 0.106      |\n","|    learning_rate   | 0.001      |\n","|    n_updates       | 39029      |\n","|    reward          | -1.2303032 |\n","-----------------------------------\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 36         |\n","|    fps             | 22         |\n","|    time_elapsed    | 1982       |\n","|    total_timesteps | 45324      |\n","| train/             |            |\n","|    actor_loss      | -7.46      |\n","|    critic_loss     | 0.0868     |\n","|    learning_rate   | 0.001      |\n","|    n_updates       | 44065      |\n","|    reward          | -1.2303032 |\n","-----------------------------------\n","day: 1258, episode: 80\n","begin_total_asset: 1000000.00\n","end_total_asset: 2326458.37\n","total_reward: 1326458.37\n","total_cost: 998.99\n","total_trades: 25149\n","Sharpe: 1.432\n","=================================\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 40         |\n","|    fps             | 22         |\n","|    time_elapsed    | 2220       |\n","|    total_timesteps | 50360      |\n","| train/             |            |\n","|    actor_loss      | -7.92      |\n","|    critic_loss     | 0.0789     |\n","|    learning_rate   | 0.001      |\n","|    n_updates       | 49101      |\n","|    reward          | -1.2303032 |\n","-----------------------------------\n","{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n","Using cpu device\n","Logging to results/ppo\n","----------------------------------\n","| time/              |           |\n","|    fps             | 131       |\n","|    iterations      | 1         |\n","|    time_elapsed    | 15        |\n","|    total_timesteps | 2048      |\n","| train/             |           |\n","|    reward          | 1.8697299 |\n","----------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 126         |\n","|    iterations           | 2           |\n","|    time_elapsed         | 32          |\n","|    total_timesteps      | 4096        |\n","| train/                  |             |\n","|    approx_kl            | 0.019335784 |\n","|    clip_fraction        | 0.226       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.2       |\n","|    explained_variance   | -0.0485     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 1.48        |\n","|    n_updates            | 10          |\n","|    policy_gradient_loss | -0.0364     |\n","|    reward               | 1.6297616   |\n","|    std                  | 1           |\n","|    value_loss           | 5.01        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 128         |\n","|    iterations           | 3           |\n","|    time_elapsed         | 47          |\n","|    total_timesteps      | 6144        |\n","| train/                  |             |\n","|    approx_kl            | 0.015270829 |\n","|    clip_fraction        | 0.192       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.2       |\n","|    explained_variance   | 0.00359     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 2.39        |\n","|    n_updates            | 20          |\n","|    policy_gradient_loss | -0.0276     |\n","|    reward               | 0.035058115 |\n","|    std                  | 1           |\n","|    value_loss           | 5.65        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 130         |\n","|    iterations           | 4           |\n","|    time_elapsed         | 62          |\n","|    total_timesteps      | 8192        |\n","| train/                  |             |\n","|    approx_kl            | 0.016161442 |\n","|    clip_fraction        | 0.184       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.3       |\n","|    explained_variance   | -0.0343     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 2.88        |\n","|    n_updates            | 30          |\n","|    policy_gradient_loss | -0.0282     |\n","|    reward               | 0.5337535   |\n","|    std                  | 1.01        |\n","|    value_loss           | 6.06        |\n","-----------------------------------------\n","day: 1258, episode: 90\n","begin_total_asset: 1000000.00\n","end_total_asset: 1816176.22\n","total_reward: 816176.22\n","total_cost: 137441.24\n","total_trades: 33831\n","Sharpe: 1.124\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 129         |\n","|    iterations           | 5           |\n","|    time_elapsed         | 78          |\n","|    total_timesteps      | 10240       |\n","| train/                  |             |\n","|    approx_kl            | 0.017217908 |\n","|    clip_fraction        | 0.223       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.4       |\n","|    explained_variance   | -0.0117     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 1.59        |\n","|    n_updates            | 40          |\n","|    policy_gradient_loss | -0.0281     |\n","|    reward               | 0.48450133  |\n","|    std                  | 1.01        |\n","|    value_loss           | 4.85        |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 128        |\n","|    iterations           | 6          |\n","|    time_elapsed         | 95         |\n","|    total_timesteps      | 12288      |\n","| train/                  |            |\n","|    approx_kl            | 0.02366223 |\n","|    clip_fraction        | 0.216      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -41.4      |\n","|    explained_variance   | -0.0458    |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 3.49       |\n","|    n_updates            | 50         |\n","|    policy_gradient_loss | -0.0259    |\n","|    reward               | 0.22944908 |\n","|    std                  | 1.01       |\n","|    value_loss           | 7.46       |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 128         |\n","|    iterations           | 7           |\n","|    time_elapsed         | 111         |\n","|    total_timesteps      | 14336       |\n","| train/                  |             |\n","|    approx_kl            | 0.019550722 |\n","|    clip_fraction        | 0.242       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.5       |\n","|    explained_variance   | -0.0179     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 2.76        |\n","|    n_updates            | 60          |\n","|    policy_gradient_loss | -0.0277     |\n","|    reward               | -0.5573856  |\n","|    std                  | 1.01        |\n","|    value_loss           | 6.66        |\n","-----------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 122          |\n","|    iterations           | 8            |\n","|    time_elapsed         | 134          |\n","|    total_timesteps      | 16384        |\n","| train/                  |              |\n","|    approx_kl            | 0.020747446  |\n","|    clip_fraction        | 0.236        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -41.5        |\n","|    explained_variance   | -0.0256      |\n","|    learning_rate        | 0.00025      |\n","|    loss                 | 2.12         |\n","|    n_updates            | 70           |\n","|    policy_gradient_loss | -0.0245      |\n","|    reward               | -0.011348645 |\n","|    std                  | 1.01         |\n","|    value_loss           | 5.92         |\n","------------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 120        |\n","|    iterations           | 9          |\n","|    time_elapsed         | 152        |\n","|    total_timesteps      | 18432      |\n","| train/                  |            |\n","|    approx_kl            | 0.02133613 |\n","|    clip_fraction        | 0.223      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -41.5      |\n","|    explained_variance   | -0.0295    |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 3.53       |\n","|    n_updates            | 80         |\n","|    policy_gradient_loss | -0.0218    |\n","|    reward               | 0.62212914 |\n","|    std                  | 1.01       |\n","|    value_loss           | 7.29       |\n","----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 121        |\n","|    iterations           | 10         |\n","|    time_elapsed         | 167        |\n","|    total_timesteps      | 20480      |\n","| train/                  |            |\n","|    approx_kl            | 0.02643501 |\n","|    clip_fraction        | 0.258      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -41.6      |\n","|    explained_variance   | -0.0656    |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 2.57       |\n","|    n_updates            | 90         |\n","|    policy_gradient_loss | -0.0305    |\n","|    reward               | 0.2993725  |\n","|    std                  | 1.02       |\n","|    value_loss           | 6.52       |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 123         |\n","|    iterations           | 11          |\n","|    time_elapsed         | 182         |\n","|    total_timesteps      | 22528       |\n","| train/                  |             |\n","|    approx_kl            | 0.024444496 |\n","|    clip_fraction        | 0.267       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.6       |\n","|    explained_variance   | 0.0458      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 1.66        |\n","|    n_updates            | 100         |\n","|    policy_gradient_loss | -0.0268     |\n","|    reward               | 0.8324868   |\n","|    std                  | 1.02        |\n","|    value_loss           | 4.64        |\n","-----------------------------------------\n","day: 1258, episode: 100\n","begin_total_asset: 1000000.00\n","end_total_asset: 2171310.27\n","total_reward: 1171310.27\n","total_cost: 140795.89\n","total_trades: 34000\n","Sharpe: 1.351\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 123         |\n","|    iterations           | 12          |\n","|    time_elapsed         | 198         |\n","|    total_timesteps      | 24576       |\n","| train/                  |             |\n","|    approx_kl            | 0.020326043 |\n","|    clip_fraction        | 0.217       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.7       |\n","|    explained_variance   | 0.0731      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 2.68        |\n","|    n_updates            | 110         |\n","|    policy_gradient_loss | -0.0209     |\n","|    reward               | 1.4292896   |\n","|    std                  | 1.02        |\n","|    value_loss           | 6.23        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 123         |\n","|    iterations           | 13          |\n","|    time_elapsed         | 215         |\n","|    total_timesteps      | 26624       |\n","| train/                  |             |\n","|    approx_kl            | 0.028905053 |\n","|    clip_fraction        | 0.268       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.7       |\n","|    explained_variance   | 0.0808      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 2.23        |\n","|    n_updates            | 120         |\n","|    policy_gradient_loss | -0.0209     |\n","|    reward               | 0.37207395  |\n","|    std                  | 1.02        |\n","|    value_loss           | 6.1         |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 123        |\n","|    iterations           | 14         |\n","|    time_elapsed         | 232        |\n","|    total_timesteps      | 28672      |\n","| train/                  |            |\n","|    approx_kl            | 0.02278566 |\n","|    clip_fraction        | 0.243      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -41.8      |\n","|    explained_variance   | -0.0433    |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 2.31       |\n","|    n_updates            | 130        |\n","|    policy_gradient_loss | -0.0172    |\n","|    reward               | 0.57933843 |\n","|    std                  | 1.02       |\n","|    value_loss           | 6.27       |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 123         |\n","|    iterations           | 15          |\n","|    time_elapsed         | 248         |\n","|    total_timesteps      | 30720       |\n","| train/                  |             |\n","|    approx_kl            | 0.02558724  |\n","|    clip_fraction        | 0.277       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.8       |\n","|    explained_variance   | -0.0121     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 2.45        |\n","|    n_updates            | 140         |\n","|    policy_gradient_loss | -0.0236     |\n","|    reward               | 0.023810335 |\n","|    std                  | 1.02        |\n","|    value_loss           | 6.32        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 123         |\n","|    iterations           | 16          |\n","|    time_elapsed         | 265         |\n","|    total_timesteps      | 32768       |\n","| train/                  |             |\n","|    approx_kl            | 0.022670649 |\n","|    clip_fraction        | 0.243       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.9       |\n","|    explained_variance   | 0.0263      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 1.6         |\n","|    n_updates            | 150         |\n","|    policy_gradient_loss | -0.0227     |\n","|    reward               | -0.29550555 |\n","|    std                  | 1.03        |\n","|    value_loss           | 4.84        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 123         |\n","|    iterations           | 17          |\n","|    time_elapsed         | 280         |\n","|    total_timesteps      | 34816       |\n","| train/                  |             |\n","|    approx_kl            | 0.021761417 |\n","|    clip_fraction        | 0.211       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.9       |\n","|    explained_variance   | 0.101       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 1.93        |\n","|    n_updates            | 160         |\n","|    policy_gradient_loss | -0.0227     |\n","|    reward               | -0.51620054 |\n","|    std                  | 1.03        |\n","|    value_loss           | 5.63        |\n","-----------------------------------------\n","day: 1258, episode: 110\n","begin_total_asset: 1000000.00\n","end_total_asset: 1959797.83\n","total_reward: 959797.83\n","total_cost: 138976.34\n","total_trades: 33919\n","Sharpe: 1.178\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 124         |\n","|    iterations           | 18          |\n","|    time_elapsed         | 296         |\n","|    total_timesteps      | 36864       |\n","| train/                  |             |\n","|    approx_kl            | 0.025476238 |\n","|    clip_fraction        | 0.236       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42         |\n","|    explained_variance   | 0.0157      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 2.14        |\n","|    n_updates            | 170         |\n","|    policy_gradient_loss | -0.0214     |\n","|    reward               | 0.3373369   |\n","|    std                  | 1.03        |\n","|    value_loss           | 5.62        |\n","-----------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 124          |\n","|    iterations           | 19           |\n","|    time_elapsed         | 311          |\n","|    total_timesteps      | 38912        |\n","| train/                  |              |\n","|    approx_kl            | 0.024943572  |\n","|    clip_fraction        | 0.223        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -42          |\n","|    explained_variance   | 0.168        |\n","|    learning_rate        | 0.00025      |\n","|    loss                 | 1.26         |\n","|    n_updates            | 180          |\n","|    policy_gradient_loss | -0.0208      |\n","|    reward               | -0.122575484 |\n","|    std                  | 1.03         |\n","|    value_loss           | 4.38         |\n","------------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 124         |\n","|    iterations           | 20          |\n","|    time_elapsed         | 328         |\n","|    total_timesteps      | 40960       |\n","| train/                  |             |\n","|    approx_kl            | 0.022791127 |\n","|    clip_fraction        | 0.195       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.1       |\n","|    explained_variance   | 0.0299      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 3.19        |\n","|    n_updates            | 190         |\n","|    policy_gradient_loss | -0.0243     |\n","|    reward               | 2.103068    |\n","|    std                  | 1.03        |\n","|    value_loss           | 6.98        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 124         |\n","|    iterations           | 21          |\n","|    time_elapsed         | 344         |\n","|    total_timesteps      | 43008       |\n","| train/                  |             |\n","|    approx_kl            | 0.026473122 |\n","|    clip_fraction        | 0.262       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.2       |\n","|    explained_variance   | 0.0759      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 2.36        |\n","|    n_updates            | 200         |\n","|    policy_gradient_loss | -0.0219     |\n","|    reward               | -0.04274529 |\n","|    std                  | 1.04        |\n","|    value_loss           | 6.29        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 124         |\n","|    iterations           | 22          |\n","|    time_elapsed         | 361         |\n","|    total_timesteps      | 45056       |\n","| train/                  |             |\n","|    approx_kl            | 0.021841824 |\n","|    clip_fraction        | 0.219       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.2       |\n","|    explained_variance   | 0.108       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 3.59        |\n","|    n_updates            | 210         |\n","|    policy_gradient_loss | -0.0184     |\n","|    reward               | 2.6953487   |\n","|    std                  | 1.04        |\n","|    value_loss           | 8.34        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 124         |\n","|    iterations           | 23          |\n","|    time_elapsed         | 378         |\n","|    total_timesteps      | 47104       |\n","| train/                  |             |\n","|    approx_kl            | 0.020716444 |\n","|    clip_fraction        | 0.202       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.3       |\n","|    explained_variance   | 0.172       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 3.71        |\n","|    n_updates            | 220         |\n","|    policy_gradient_loss | -0.0235     |\n","|    reward               | 1.7714319   |\n","|    std                  | 1.04        |\n","|    value_loss           | 8.07        |\n","-----------------------------------------\n","day: 1258, episode: 120\n","begin_total_asset: 1000000.00\n","end_total_asset: 2542733.79\n","total_reward: 1542733.79\n","total_cost: 115187.33\n","total_trades: 31939\n","Sharpe: 1.406\n","=================================\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 124        |\n","|    iterations           | 24         |\n","|    time_elapsed         | 394        |\n","|    total_timesteps      | 49152      |\n","| train/                  |            |\n","|    approx_kl            | 0.02188178 |\n","|    clip_fraction        | 0.202      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -42.3      |\n","|    explained_variance   | 0.253      |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 2.93       |\n","|    n_updates            | 230        |\n","|    policy_gradient_loss | -0.0152    |\n","|    reward               | -0.5241831 |\n","|    std                  | 1.04       |\n","|    value_loss           | 6.73       |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 124         |\n","|    iterations           | 25          |\n","|    time_elapsed         | 410         |\n","|    total_timesteps      | 51200       |\n","| train/                  |             |\n","|    approx_kl            | 0.023185845 |\n","|    clip_fraction        | 0.225       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.3       |\n","|    explained_variance   | 0.0413      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 5.06        |\n","|    n_updates            | 240         |\n","|    policy_gradient_loss | -0.0159     |\n","|    reward               | -1.0956562  |\n","|    std                  | 1.04        |\n","|    value_loss           | 14          |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 26          |\n","|    time_elapsed         | 425         |\n","|    total_timesteps      | 53248       |\n","| train/                  |             |\n","|    approx_kl            | 0.019106956 |\n","|    clip_fraction        | 0.205       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.4       |\n","|    explained_variance   | 0.201       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 4.33        |\n","|    n_updates            | 250         |\n","|    policy_gradient_loss | -0.0152     |\n","|    reward               | -0.348504   |\n","|    std                  | 1.04        |\n","|    value_loss           | 10.5        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 27          |\n","|    time_elapsed         | 441         |\n","|    total_timesteps      | 55296       |\n","| train/                  |             |\n","|    approx_kl            | 0.017107658 |\n","|    clip_fraction        | 0.202       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.4       |\n","|    explained_variance   | 0.0461      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 4.41        |\n","|    n_updates            | 260         |\n","|    policy_gradient_loss | -0.0171     |\n","|    reward               | -2.3938947  |\n","|    std                  | 1.04        |\n","|    value_loss           | 11.3        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 28          |\n","|    time_elapsed         | 457         |\n","|    total_timesteps      | 57344       |\n","| train/                  |             |\n","|    approx_kl            | 0.014270263 |\n","|    clip_fraction        | 0.117       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.4       |\n","|    explained_variance   | 0.142       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 4.62        |\n","|    n_updates            | 270         |\n","|    policy_gradient_loss | -0.011      |\n","|    reward               | -2.801332   |\n","|    std                  | 1.04        |\n","|    value_loss           | 13.5        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 124         |\n","|    iterations           | 29          |\n","|    time_elapsed         | 478         |\n","|    total_timesteps      | 59392       |\n","| train/                  |             |\n","|    approx_kl            | 0.025377177 |\n","|    clip_fraction        | 0.217       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.4       |\n","|    explained_variance   | 0.127       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 5.75        |\n","|    n_updates            | 280         |\n","|    policy_gradient_loss | -0.0128     |\n","|    reward               | 0.41875836  |\n","|    std                  | 1.05        |\n","|    value_loss           | 11.9        |\n","-----------------------------------------\n","day: 1258, episode: 130\n","begin_total_asset: 1000000.00\n","end_total_asset: 2245960.18\n","total_reward: 1245960.18\n","total_cost: 120394.78\n","total_trades: 32083\n","Sharpe: 1.297\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 124         |\n","|    iterations           | 30          |\n","|    time_elapsed         | 494         |\n","|    total_timesteps      | 61440       |\n","| train/                  |             |\n","|    approx_kl            | 0.020462634 |\n","|    clip_fraction        | 0.229       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.4       |\n","|    explained_variance   | 0.188       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 8.53        |\n","|    n_updates            | 290         |\n","|    policy_gradient_loss | -0.0137     |\n","|    reward               | 0.9223305   |\n","|    std                  | 1.05        |\n","|    value_loss           | 15.2        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 124         |\n","|    iterations           | 31          |\n","|    time_elapsed         | 510         |\n","|    total_timesteps      | 63488       |\n","| train/                  |             |\n","|    approx_kl            | 0.020859018 |\n","|    clip_fraction        | 0.237       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.5       |\n","|    explained_variance   | 0.205       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 3.79        |\n","|    n_updates            | 300         |\n","|    policy_gradient_loss | -0.0198     |\n","|    reward               | -1.7191427  |\n","|    std                  | 1.05        |\n","|    value_loss           | 9.28        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 124         |\n","|    iterations           | 32          |\n","|    time_elapsed         | 525         |\n","|    total_timesteps      | 65536       |\n","| train/                  |             |\n","|    approx_kl            | 0.015171054 |\n","|    clip_fraction        | 0.145       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.5       |\n","|    explained_variance   | 0.295       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 6.27        |\n","|    n_updates            | 310         |\n","|    policy_gradient_loss | -0.0234     |\n","|    reward               | 0.4970963   |\n","|    std                  | 1.05        |\n","|    value_loss           | 12.4        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 33          |\n","|    time_elapsed         | 540         |\n","|    total_timesteps      | 67584       |\n","| train/                  |             |\n","|    approx_kl            | 0.028845944 |\n","|    clip_fraction        | 0.276       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.5       |\n","|    explained_variance   | 0.42        |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 2.38        |\n","|    n_updates            | 320         |\n","|    policy_gradient_loss | -0.0226     |\n","|    reward               | 0.21496165  |\n","|    std                  | 1.05        |\n","|    value_loss           | 7.62        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 34          |\n","|    time_elapsed         | 556         |\n","|    total_timesteps      | 69632       |\n","| train/                  |             |\n","|    approx_kl            | 0.020053335 |\n","|    clip_fraction        | 0.217       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.5       |\n","|    explained_variance   | 0.324       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 4.08        |\n","|    n_updates            | 330         |\n","|    policy_gradient_loss | -0.0151     |\n","|    reward               | -0.8343454  |\n","|    std                  | 1.05        |\n","|    value_loss           | 12.2        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 124         |\n","|    iterations           | 35          |\n","|    time_elapsed         | 573         |\n","|    total_timesteps      | 71680       |\n","| train/                  |             |\n","|    approx_kl            | 0.024795286 |\n","|    clip_fraction        | 0.266       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.6       |\n","|    explained_variance   | 0.447       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 2.76        |\n","|    n_updates            | 340         |\n","|    policy_gradient_loss | -0.0242     |\n","|    reward               | 0.48101267  |\n","|    std                  | 1.05        |\n","|    value_loss           | 8.58        |\n","-----------------------------------------\n","day: 1258, episode: 140\n","begin_total_asset: 1000000.00\n","end_total_asset: 2498311.72\n","total_reward: 1498311.72\n","total_cost: 115833.05\n","total_trades: 31778\n","Sharpe: 1.385\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 124         |\n","|    iterations           | 36          |\n","|    time_elapsed         | 590         |\n","|    total_timesteps      | 73728       |\n","| train/                  |             |\n","|    approx_kl            | 0.026332617 |\n","|    clip_fraction        | 0.246       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.7       |\n","|    explained_variance   | 0.406       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 4.67        |\n","|    n_updates            | 350         |\n","|    policy_gradient_loss | -0.014      |\n","|    reward               | 0.68421793  |\n","|    std                  | 1.06        |\n","|    value_loss           | 9.22        |\n","-----------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 124           |\n","|    iterations           | 37            |\n","|    time_elapsed         | 607           |\n","|    total_timesteps      | 75776         |\n","| train/                  |               |\n","|    approx_kl            | 0.023646127   |\n","|    clip_fraction        | 0.212         |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -42.8         |\n","|    explained_variance   | 0.459         |\n","|    learning_rate        | 0.00025       |\n","|    loss                 | 5.08          |\n","|    n_updates            | 360           |\n","|    policy_gradient_loss | -0.0166       |\n","|    reward               | -0.0040054284 |\n","|    std                  | 1.06          |\n","|    value_loss           | 10.9          |\n","-------------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 124         |\n","|    iterations           | 38          |\n","|    time_elapsed         | 623         |\n","|    total_timesteps      | 77824       |\n","| train/                  |             |\n","|    approx_kl            | 0.030988902 |\n","|    clip_fraction        | 0.285       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.8       |\n","|    explained_variance   | 0.437       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 6.5         |\n","|    n_updates            | 370         |\n","|    policy_gradient_loss | -0.0126     |\n","|    reward               | 0.051465087 |\n","|    std                  | 1.06        |\n","|    value_loss           | 13.1        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 39          |\n","|    time_elapsed         | 638         |\n","|    total_timesteps      | 79872       |\n","| train/                  |             |\n","|    approx_kl            | 0.024916504 |\n","|    clip_fraction        | 0.227       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.9       |\n","|    explained_variance   | 0.384       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 3.77        |\n","|    n_updates            | 380         |\n","|    policy_gradient_loss | -0.019      |\n","|    reward               | 1.591851    |\n","|    std                  | 1.06        |\n","|    value_loss           | 10          |\n","-----------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 125          |\n","|    iterations           | 40           |\n","|    time_elapsed         | 653          |\n","|    total_timesteps      | 81920        |\n","| train/                  |              |\n","|    approx_kl            | 0.025360314  |\n","|    clip_fraction        | 0.293        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -43          |\n","|    explained_variance   | 0.45         |\n","|    learning_rate        | 0.00025      |\n","|    loss                 | 4.7          |\n","|    n_updates            | 390          |\n","|    policy_gradient_loss | -0.0194      |\n","|    reward               | -0.044020217 |\n","|    std                  | 1.07         |\n","|    value_loss           | 11.8         |\n","------------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 41          |\n","|    time_elapsed         | 669         |\n","|    total_timesteps      | 83968       |\n","| train/                  |             |\n","|    approx_kl            | 0.04185362  |\n","|    clip_fraction        | 0.228       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43         |\n","|    explained_variance   | 0.453       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 5.29        |\n","|    n_updates            | 400         |\n","|    policy_gradient_loss | -0.00476    |\n","|    reward               | -0.06092972 |\n","|    std                  | 1.07        |\n","|    value_loss           | 12.6        |\n","-----------------------------------------\n","day: 1258, episode: 150\n","begin_total_asset: 1000000.00\n","end_total_asset: 2723565.08\n","total_reward: 1723565.08\n","total_cost: 100904.54\n","total_trades: 30582\n","Sharpe: 1.450\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 42          |\n","|    time_elapsed         | 686         |\n","|    total_timesteps      | 86016       |\n","| train/                  |             |\n","|    approx_kl            | 0.019468864 |\n","|    clip_fraction        | 0.176       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43         |\n","|    explained_variance   | 0.434       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 7.34        |\n","|    n_updates            | 410         |\n","|    policy_gradient_loss | -0.0124     |\n","|    reward               | 0.122434676 |\n","|    std                  | 1.07        |\n","|    value_loss           | 13.1        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 43          |\n","|    time_elapsed         | 702         |\n","|    total_timesteps      | 88064       |\n","| train/                  |             |\n","|    approx_kl            | 0.020752668 |\n","|    clip_fraction        | 0.26        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.1       |\n","|    explained_variance   | 0.566       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 5.13        |\n","|    n_updates            | 420         |\n","|    policy_gradient_loss | -0.00899    |\n","|    reward               | 1.3371617   |\n","|    std                  | 1.07        |\n","|    value_loss           | 14.6        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 44          |\n","|    time_elapsed         | 719         |\n","|    total_timesteps      | 90112       |\n","| train/                  |             |\n","|    approx_kl            | 0.016030096 |\n","|    clip_fraction        | 0.182       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.2       |\n","|    explained_variance   | 0.481       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 8.47        |\n","|    n_updates            | 430         |\n","|    policy_gradient_loss | -0.0151     |\n","|    reward               | -0.6789468  |\n","|    std                  | 1.07        |\n","|    value_loss           | 16.1        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 45          |\n","|    time_elapsed         | 736         |\n","|    total_timesteps      | 92160       |\n","| train/                  |             |\n","|    approx_kl            | 0.017737538 |\n","|    clip_fraction        | 0.195       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.2       |\n","|    explained_variance   | 0.493       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 6.95        |\n","|    n_updates            | 440         |\n","|    policy_gradient_loss | -0.0198     |\n","|    reward               | 0.1924967   |\n","|    std                  | 1.07        |\n","|    value_loss           | 14          |\n","-----------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 125          |\n","|    iterations           | 46           |\n","|    time_elapsed         | 751          |\n","|    total_timesteps      | 94208        |\n","| train/                  |              |\n","|    approx_kl            | 0.023155944  |\n","|    clip_fraction        | 0.137        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -43.2        |\n","|    explained_variance   | 0.529        |\n","|    learning_rate        | 0.00025      |\n","|    loss                 | 6.7          |\n","|    n_updates            | 450          |\n","|    policy_gradient_loss | -0.00807     |\n","|    reward               | -0.029579066 |\n","|    std                  | 1.08         |\n","|    value_loss           | 19.4         |\n","------------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 47          |\n","|    time_elapsed         | 766         |\n","|    total_timesteps      | 96256       |\n","| train/                  |             |\n","|    approx_kl            | 0.043305784 |\n","|    clip_fraction        | 0.302       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.3       |\n","|    explained_variance   | 0.42        |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 6.66        |\n","|    n_updates            | 460         |\n","|    policy_gradient_loss | -0.00862    |\n","|    reward               | -0.5504839  |\n","|    std                  | 1.08        |\n","|    value_loss           | 14.9        |\n","-----------------------------------------\n","day: 1258, episode: 160\n","begin_total_asset: 1000000.00\n","end_total_asset: 2755804.97\n","total_reward: 1755804.97\n","total_cost: 76190.89\n","total_trades: 28085\n","Sharpe: 1.404\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 48          |\n","|    time_elapsed         | 782         |\n","|    total_timesteps      | 98304       |\n","| train/                  |             |\n","|    approx_kl            | 0.028410535 |\n","|    clip_fraction        | 0.247       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.3       |\n","|    explained_variance   | 0.512       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 6.07        |\n","|    n_updates            | 470         |\n","|    policy_gradient_loss | -0.00855    |\n","|    reward               | 0.555424    |\n","|    std                  | 1.08        |\n","|    value_loss           | 17.9        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 124         |\n","|    iterations           | 49          |\n","|    time_elapsed         | 803         |\n","|    total_timesteps      | 100352      |\n","| train/                  |             |\n","|    approx_kl            | 0.011133429 |\n","|    clip_fraction        | 0.14        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.3       |\n","|    explained_variance   | 0.502       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 10.7        |\n","|    n_updates            | 480         |\n","|    policy_gradient_loss | -0.0112     |\n","|    reward               | 0.4398638   |\n","|    std                  | 1.08        |\n","|    value_loss           | 23.1        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 124         |\n","|    iterations           | 50          |\n","|    time_elapsed         | 819         |\n","|    total_timesteps      | 102400      |\n","| train/                  |             |\n","|    approx_kl            | 0.01918466  |\n","|    clip_fraction        | 0.269       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.4       |\n","|    explained_variance   | 0.542       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 9.08        |\n","|    n_updates            | 490         |\n","|    policy_gradient_loss | -0.0131     |\n","|    reward               | -0.13194941 |\n","|    std                  | 1.08        |\n","|    value_loss           | 15.3        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 124         |\n","|    iterations           | 51          |\n","|    time_elapsed         | 836         |\n","|    total_timesteps      | 104448      |\n","| train/                  |             |\n","|    approx_kl            | 0.014018588 |\n","|    clip_fraction        | 0.141       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.4       |\n","|    explained_variance   | 0.634       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 4.62        |\n","|    n_updates            | 500         |\n","|    policy_gradient_loss | -0.0156     |\n","|    reward               | 4.974349    |\n","|    std                  | 1.08        |\n","|    value_loss           | 17.7        |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 124        |\n","|    iterations           | 52         |\n","|    time_elapsed         | 853        |\n","|    total_timesteps      | 106496     |\n","| train/                  |            |\n","|    approx_kl            | 0.02085189 |\n","|    clip_fraction        | 0.16       |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -43.4      |\n","|    explained_variance   | 0.653      |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 10.2       |\n","|    n_updates            | 510        |\n","|    policy_gradient_loss | -0.0167    |\n","|    reward               | -1.058045  |\n","|    std                  | 1.08       |\n","|    value_loss           | 18         |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 124         |\n","|    iterations           | 53          |\n","|    time_elapsed         | 869         |\n","|    total_timesteps      | 108544      |\n","| train/                  |             |\n","|    approx_kl            | 0.024730414 |\n","|    clip_fraction        | 0.247       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.4       |\n","|    explained_variance   | 0.633       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 11.2        |\n","|    n_updates            | 520         |\n","|    policy_gradient_loss | -0.00395    |\n","|    reward               | -2.1753614  |\n","|    std                  | 1.08        |\n","|    value_loss           | 18          |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 124        |\n","|    iterations           | 54         |\n","|    time_elapsed         | 886        |\n","|    total_timesteps      | 110592     |\n","| train/                  |            |\n","|    approx_kl            | 0.01140727 |\n","|    clip_fraction        | 0.119      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -43.4      |\n","|    explained_variance   | 0.637      |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 9.76       |\n","|    n_updates            | 530        |\n","|    policy_gradient_loss | -0.0126    |\n","|    reward               | 1.5959843  |\n","|    std                  | 1.08       |\n","|    value_loss           | 21.9       |\n","----------------------------------------\n","day: 1258, episode: 170\n","begin_total_asset: 1000000.00\n","end_total_asset: 2772852.76\n","total_reward: 1772852.76\n","total_cost: 65281.19\n","total_trades: 27519\n","Sharpe: 1.313\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 124         |\n","|    iterations           | 55          |\n","|    time_elapsed         | 902         |\n","|    total_timesteps      | 112640      |\n","| train/                  |             |\n","|    approx_kl            | 0.012745613 |\n","|    clip_fraction        | 0.154       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.5       |\n","|    explained_variance   | 0.615       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 7.9         |\n","|    n_updates            | 540         |\n","|    policy_gradient_loss | -0.013      |\n","|    reward               | -0.75503147 |\n","|    std                  | 1.08        |\n","|    value_loss           | 18.8        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 56          |\n","|    time_elapsed         | 917         |\n","|    total_timesteps      | 114688      |\n","| train/                  |             |\n","|    approx_kl            | 0.018966436 |\n","|    clip_fraction        | 0.199       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.5       |\n","|    explained_variance   | 0.667       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 11.3        |\n","|    n_updates            | 550         |\n","|    policy_gradient_loss | -0.00765    |\n","|    reward               | -1.9121199  |\n","|    std                  | 1.09        |\n","|    value_loss           | 22          |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 57          |\n","|    time_elapsed         | 932         |\n","|    total_timesteps      | 116736      |\n","| train/                  |             |\n","|    approx_kl            | 0.014859768 |\n","|    clip_fraction        | 0.158       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.6       |\n","|    explained_variance   | 0.664       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 12.1        |\n","|    n_updates            | 560         |\n","|    policy_gradient_loss | -0.0091     |\n","|    reward               | 0.7626451   |\n","|    std                  | 1.09        |\n","|    value_loss           | 24.9        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 58          |\n","|    time_elapsed         | 948         |\n","|    total_timesteps      | 118784      |\n","| train/                  |             |\n","|    approx_kl            | 0.022622455 |\n","|    clip_fraction        | 0.235       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.6       |\n","|    explained_variance   | 0.489       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 7.97        |\n","|    n_updates            | 570         |\n","|    policy_gradient_loss | -0.00166    |\n","|    reward               | -0.06963682 |\n","|    std                  | 1.09        |\n","|    value_loss           | 19          |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 59          |\n","|    time_elapsed         | 965         |\n","|    total_timesteps      | 120832      |\n","| train/                  |             |\n","|    approx_kl            | 0.022127397 |\n","|    clip_fraction        | 0.257       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.7       |\n","|    explained_variance   | 0.699       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 8.69        |\n","|    n_updates            | 580         |\n","|    policy_gradient_loss | -0.00495    |\n","|    reward               | -0.88857764 |\n","|    std                  | 1.09        |\n","|    value_loss           | 22.8        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 60          |\n","|    time_elapsed         | 981         |\n","|    total_timesteps      | 122880      |\n","| train/                  |             |\n","|    approx_kl            | 0.019864514 |\n","|    clip_fraction        | 0.203       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.7       |\n","|    explained_variance   | 0.695       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 12          |\n","|    n_updates            | 590         |\n","|    policy_gradient_loss | -0.0046     |\n","|    reward               | 0.8542277   |\n","|    std                  | 1.09        |\n","|    value_loss           | 22.6        |\n","-----------------------------------------\n","day: 1258, episode: 180\n","begin_total_asset: 1000000.00\n","end_total_asset: 3047962.72\n","total_reward: 2047962.72\n","total_cost: 70880.12\n","total_trades: 27796\n","Sharpe: 1.475\n","=================================\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 125          |\n","|    iterations           | 61           |\n","|    time_elapsed         | 998          |\n","|    total_timesteps      | 124928       |\n","| train/                  |              |\n","|    approx_kl            | 0.0113990465 |\n","|    clip_fraction        | 0.126        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -43.8        |\n","|    explained_variance   | 0.68         |\n","|    learning_rate        | 0.00025      |\n","|    loss                 | 5.38         |\n","|    n_updates            | 600          |\n","|    policy_gradient_loss | -0.0135      |\n","|    reward               | 1.5579679    |\n","|    std                  | 1.1          |\n","|    value_loss           | 19.6         |\n","------------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 62          |\n","|    time_elapsed         | 1014        |\n","|    total_timesteps      | 126976      |\n","| train/                  |             |\n","|    approx_kl            | 0.016422948 |\n","|    clip_fraction        | 0.177       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.8       |\n","|    explained_variance   | 0.691       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 13.3        |\n","|    n_updates            | 610         |\n","|    policy_gradient_loss | -0.00632    |\n","|    reward               | 0.9888608   |\n","|    std                  | 1.1         |\n","|    value_loss           | 24.7        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 63          |\n","|    time_elapsed         | 1030        |\n","|    total_timesteps      | 129024      |\n","| train/                  |             |\n","|    approx_kl            | 0.014294613 |\n","|    clip_fraction        | 0.174       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.8       |\n","|    explained_variance   | 0.708       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 7.77        |\n","|    n_updates            | 620         |\n","|    policy_gradient_loss | -0.0111     |\n","|    reward               | 0.4952756   |\n","|    std                  | 1.1         |\n","|    value_loss           | 20.5        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 64          |\n","|    time_elapsed         | 1045        |\n","|    total_timesteps      | 131072      |\n","| train/                  |             |\n","|    approx_kl            | 0.011873487 |\n","|    clip_fraction        | 0.141       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.9       |\n","|    explained_variance   | 0.732       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 10          |\n","|    n_updates            | 630         |\n","|    policy_gradient_loss | -0.0159     |\n","|    reward               | 1.7660657   |\n","|    std                  | 1.1         |\n","|    value_loss           | 25.1        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 65          |\n","|    time_elapsed         | 1061        |\n","|    total_timesteps      | 133120      |\n","| train/                  |             |\n","|    approx_kl            | 0.017919794 |\n","|    clip_fraction        | 0.127       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.9       |\n","|    explained_variance   | 0.708       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 8.88        |\n","|    n_updates            | 640         |\n","|    policy_gradient_loss | -0.01       |\n","|    reward               | 1.2843984   |\n","|    std                  | 1.1         |\n","|    value_loss           | 26.3        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 66          |\n","|    time_elapsed         | 1077        |\n","|    total_timesteps      | 135168      |\n","| train/                  |             |\n","|    approx_kl            | 0.017169623 |\n","|    clip_fraction        | 0.205       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44         |\n","|    explained_variance   | 0.747       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 9.29        |\n","|    n_updates            | 650         |\n","|    policy_gradient_loss | -0.0127     |\n","|    reward               | -4.416204   |\n","|    std                  | 1.1         |\n","|    value_loss           | 19.1        |\n","-----------------------------------------\n","day: 1258, episode: 190\n","begin_total_asset: 1000000.00\n","end_total_asset: 2840926.66\n","total_reward: 1840926.66\n","total_cost: 65350.50\n","total_trades: 27140\n","Sharpe: 1.415\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 67          |\n","|    time_elapsed         | 1094        |\n","|    total_timesteps      | 137216      |\n","| train/                  |             |\n","|    approx_kl            | 0.020827854 |\n","|    clip_fraction        | 0.203       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44         |\n","|    explained_variance   | 0.774       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 11.3        |\n","|    n_updates            | 660         |\n","|    policy_gradient_loss | -0.014      |\n","|    reward               | 3.4908974   |\n","|    std                  | 1.1         |\n","|    value_loss           | 21.8        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 68          |\n","|    time_elapsed         | 1110        |\n","|    total_timesteps      | 139264      |\n","| train/                  |             |\n","|    approx_kl            | 0.016737286 |\n","|    clip_fraction        | 0.135       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44         |\n","|    explained_variance   | 0.705       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 8.57        |\n","|    n_updates            | 670         |\n","|    policy_gradient_loss | -0.00913    |\n","|    reward               | 2.3907845   |\n","|    std                  | 1.11        |\n","|    value_loss           | 20.6        |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 124        |\n","|    iterations           | 69         |\n","|    time_elapsed         | 1130       |\n","|    total_timesteps      | 141312     |\n","| train/                  |            |\n","|    approx_kl            | 0.06585717 |\n","|    clip_fraction        | 0.189      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -44        |\n","|    explained_variance   | 0.711      |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 10.5       |\n","|    n_updates            | 680        |\n","|    policy_gradient_loss | -0.00555   |\n","|    reward               | -1.6234322 |\n","|    std                  | 1.11       |\n","|    value_loss           | 22.2       |\n","----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 124        |\n","|    iterations           | 70         |\n","|    time_elapsed         | 1147       |\n","|    total_timesteps      | 143360     |\n","| train/                  |            |\n","|    approx_kl            | 0.08027868 |\n","|    clip_fraction        | 0.183      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -44.1      |\n","|    explained_variance   | 0.717      |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 9.89       |\n","|    n_updates            | 690        |\n","|    policy_gradient_loss | 0.00371    |\n","|    reward               | 2.05201    |\n","|    std                  | 1.11       |\n","|    value_loss           | 24.2       |\n","----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 125        |\n","|    iterations           | 71         |\n","|    time_elapsed         | 1163       |\n","|    total_timesteps      | 145408     |\n","| train/                  |            |\n","|    approx_kl            | 0.0115877  |\n","|    clip_fraction        | 0.0946     |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -44.1      |\n","|    explained_variance   | 0.691      |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 9.82       |\n","|    n_updates            | 700        |\n","|    policy_gradient_loss | -0.0111    |\n","|    reward               | -1.3466632 |\n","|    std                  | 1.11       |\n","|    value_loss           | 19.7       |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 72          |\n","|    time_elapsed         | 1178        |\n","|    total_timesteps      | 147456      |\n","| train/                  |             |\n","|    approx_kl            | 0.020926505 |\n","|    clip_fraction        | 0.171       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.2       |\n","|    explained_variance   | 0.739       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 17.5        |\n","|    n_updates            | 710         |\n","|    policy_gradient_loss | -0.00885    |\n","|    reward               | -0.52132255 |\n","|    std                  | 1.11        |\n","|    value_loss           | 21.2        |\n","-----------------------------------------\n","day: 1258, episode: 200\n","begin_total_asset: 1000000.00\n","end_total_asset: 2887843.78\n","total_reward: 1887843.78\n","total_cost: 56547.29\n","total_trades: 26267\n","Sharpe: 1.343\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 73          |\n","|    time_elapsed         | 1193        |\n","|    total_timesteps      | 149504      |\n","| train/                  |             |\n","|    approx_kl            | 0.012159927 |\n","|    clip_fraction        | 0.14        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.2       |\n","|    explained_variance   | 0.76        |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 8.52        |\n","|    n_updates            | 720         |\n","|    policy_gradient_loss | -0.00965    |\n","|    reward               | 0.42323288  |\n","|    std                  | 1.11        |\n","|    value_loss           | 21.6        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 74          |\n","|    time_elapsed         | 1209        |\n","|    total_timesteps      | 151552      |\n","| train/                  |             |\n","|    approx_kl            | 0.020147873 |\n","|    clip_fraction        | 0.204       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.2       |\n","|    explained_variance   | 0.767       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 9.55        |\n","|    n_updates            | 730         |\n","|    policy_gradient_loss | -0.0078     |\n","|    reward               | 0.30638495  |\n","|    std                  | 1.11        |\n","|    value_loss           | 18.2        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 75          |\n","|    time_elapsed         | 1225        |\n","|    total_timesteps      | 153600      |\n","| train/                  |             |\n","|    approx_kl            | 0.021421222 |\n","|    clip_fraction        | 0.276       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.3       |\n","|    explained_variance   | 0.827       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 9.98        |\n","|    n_updates            | 740         |\n","|    policy_gradient_loss | 0.00421     |\n","|    reward               | 0.06441286  |\n","|    std                  | 1.12        |\n","|    value_loss           | 18.2        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 76          |\n","|    time_elapsed         | 1242        |\n","|    total_timesteps      | 155648      |\n","| train/                  |             |\n","|    approx_kl            | 0.019009447 |\n","|    clip_fraction        | 0.195       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.3       |\n","|    explained_variance   | 0.798       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 12          |\n","|    n_updates            | 750         |\n","|    policy_gradient_loss | -0.00313    |\n","|    reward               | -0.8657636  |\n","|    std                  | 1.12        |\n","|    value_loss           | 22.7        |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 125        |\n","|    iterations           | 77         |\n","|    time_elapsed         | 1258       |\n","|    total_timesteps      | 157696     |\n","| train/                  |            |\n","|    approx_kl            | 0.04894564 |\n","|    clip_fraction        | 0.294      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -44.3      |\n","|    explained_variance   | 0.804      |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 6.27       |\n","|    n_updates            | 760        |\n","|    policy_gradient_loss | 0.000866   |\n","|    reward               | -1.4519492 |\n","|    std                  | 1.12       |\n","|    value_loss           | 15.3       |\n","----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 125        |\n","|    iterations           | 78         |\n","|    time_elapsed         | 1276       |\n","|    total_timesteps      | 159744     |\n","| train/                  |            |\n","|    approx_kl            | 0.01997567 |\n","|    clip_fraction        | 0.171      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -44.4      |\n","|    explained_variance   | 0.809      |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 9.86       |\n","|    n_updates            | 770        |\n","|    policy_gradient_loss | -0.00369   |\n","|    reward               | 0.95760185 |\n","|    std                  | 1.12       |\n","|    value_loss           | 23.2       |\n","----------------------------------------\n","day: 1258, episode: 210\n","begin_total_asset: 1000000.00\n","end_total_asset: 2900391.71\n","total_reward: 1900391.71\n","total_cost: 52212.66\n","total_trades: 26107\n","Sharpe: 1.370\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 79          |\n","|    time_elapsed         | 1291        |\n","|    total_timesteps      | 161792      |\n","| train/                  |             |\n","|    approx_kl            | 0.022531841 |\n","|    clip_fraction        | 0.309       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.4       |\n","|    explained_variance   | 0.823       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 9.55        |\n","|    n_updates            | 780         |\n","|    policy_gradient_loss | -0.000517   |\n","|    reward               | 0.17077427  |\n","|    std                  | 1.12        |\n","|    value_loss           | 16.6        |\n","-----------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 125          |\n","|    iterations           | 80           |\n","|    time_elapsed         | 1307         |\n","|    total_timesteps      | 163840       |\n","| train/                  |              |\n","|    approx_kl            | 0.016345184  |\n","|    clip_fraction        | 0.186        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -44.4        |\n","|    explained_variance   | 0.781        |\n","|    learning_rate        | 0.00025      |\n","|    loss                 | 11.3         |\n","|    n_updates            | 790          |\n","|    policy_gradient_loss | -0.0119      |\n","|    reward               | -0.025229443 |\n","|    std                  | 1.12         |\n","|    value_loss           | 21.4         |\n","------------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 81          |\n","|    time_elapsed         | 1322        |\n","|    total_timesteps      | 165888      |\n","| train/                  |             |\n","|    approx_kl            | 0.021273078 |\n","|    clip_fraction        | 0.2         |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.5       |\n","|    explained_variance   | 0.801       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 7.12        |\n","|    n_updates            | 800         |\n","|    policy_gradient_loss | -0.00713    |\n","|    reward               | -0.6979354  |\n","|    std                  | 1.12        |\n","|    value_loss           | 18.8        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 82          |\n","|    time_elapsed         | 1339        |\n","|    total_timesteps      | 167936      |\n","| train/                  |             |\n","|    approx_kl            | 0.026149757 |\n","|    clip_fraction        | 0.222       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.5       |\n","|    explained_variance   | 0.781       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 5.78        |\n","|    n_updates            | 810         |\n","|    policy_gradient_loss | -0.00974    |\n","|    reward               | -4.4227138  |\n","|    std                  | 1.12        |\n","|    value_loss           | 16.7        |\n","-----------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 125          |\n","|    iterations           | 83           |\n","|    time_elapsed         | 1356         |\n","|    total_timesteps      | 169984       |\n","| train/                  |              |\n","|    approx_kl            | 0.029555202  |\n","|    clip_fraction        | 0.257        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -44.6        |\n","|    explained_variance   | 0.705        |\n","|    learning_rate        | 0.00025      |\n","|    loss                 | 9.7          |\n","|    n_updates            | 820          |\n","|    policy_gradient_loss | -0.00305     |\n","|    reward               | -0.118796006 |\n","|    std                  | 1.13         |\n","|    value_loss           | 20.1         |\n","------------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 84          |\n","|    time_elapsed         | 1372        |\n","|    total_timesteps      | 172032      |\n","| train/                  |             |\n","|    approx_kl            | 0.010659276 |\n","|    clip_fraction        | 0.128       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.6       |\n","|    explained_variance   | 0.806       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 10.2        |\n","|    n_updates            | 830         |\n","|    policy_gradient_loss | -0.00722    |\n","|    reward               | 2.7015283   |\n","|    std                  | 1.13        |\n","|    value_loss           | 20.1        |\n","-----------------------------------------\n","day: 1258, episode: 220\n","begin_total_asset: 1000000.00\n","end_total_asset: 2727254.20\n","total_reward: 1727254.20\n","total_cost: 64203.40\n","total_trades: 27395\n","Sharpe: 1.352\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 85          |\n","|    time_elapsed         | 1389        |\n","|    total_timesteps      | 174080      |\n","| train/                  |             |\n","|    approx_kl            | 0.026907902 |\n","|    clip_fraction        | 0.275       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.6       |\n","|    explained_variance   | 0.836       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 7.13        |\n","|    n_updates            | 840         |\n","|    policy_gradient_loss | -0.0169     |\n","|    reward               | 0.6031544   |\n","|    std                  | 1.13        |\n","|    value_loss           | 14.7        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 86          |\n","|    time_elapsed         | 1406        |\n","|    total_timesteps      | 176128      |\n","| train/                  |             |\n","|    approx_kl            | 0.034649283 |\n","|    clip_fraction        | 0.28        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.7       |\n","|    explained_variance   | 0.686       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 7.75        |\n","|    n_updates            | 850         |\n","|    policy_gradient_loss | -0.000421   |\n","|    reward               | 2.024654    |\n","|    std                  | 1.13        |\n","|    value_loss           | 18.6        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 87          |\n","|    time_elapsed         | 1421        |\n","|    total_timesteps      | 178176      |\n","| train/                  |             |\n","|    approx_kl            | 0.017365608 |\n","|    clip_fraction        | 0.149       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.7       |\n","|    explained_variance   | 0.744       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 9.54        |\n","|    n_updates            | 860         |\n","|    policy_gradient_loss | -0.0108     |\n","|    reward               | -0.9858561  |\n","|    std                  | 1.13        |\n","|    value_loss           | 17.7        |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 125        |\n","|    iterations           | 88         |\n","|    time_elapsed         | 1436       |\n","|    total_timesteps      | 180224     |\n","| train/                  |            |\n","|    approx_kl            | 0.02550067 |\n","|    clip_fraction        | 0.266      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -44.8      |\n","|    explained_variance   | 0.759      |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 8.2        |\n","|    n_updates            | 870        |\n","|    policy_gradient_loss | -0.00814   |\n","|    reward               | -1.1114231 |\n","|    std                  | 1.13       |\n","|    value_loss           | 20.4       |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 89          |\n","|    time_elapsed         | 1457        |\n","|    total_timesteps      | 182272      |\n","| train/                  |             |\n","|    approx_kl            | 0.023667607 |\n","|    clip_fraction        | 0.258       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.8       |\n","|    explained_variance   | 0.754       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 9.9         |\n","|    n_updates            | 880         |\n","|    policy_gradient_loss | -0.00171    |\n","|    reward               | -0.11398743 |\n","|    std                  | 1.14        |\n","|    value_loss           | 22.5        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 90          |\n","|    time_elapsed         | 1472        |\n","|    total_timesteps      | 184320      |\n","| train/                  |             |\n","|    approx_kl            | 0.020679045 |\n","|    clip_fraction        | 0.22        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.9       |\n","|    explained_variance   | 0.782       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 7.21        |\n","|    n_updates            | 890         |\n","|    policy_gradient_loss | -0.00464    |\n","|    reward               | -0.7029747  |\n","|    std                  | 1.14        |\n","|    value_loss           | 14.5        |\n","-----------------------------------------\n","day: 1258, episode: 230\n","begin_total_asset: 1000000.00\n","end_total_asset: 2804502.81\n","total_reward: 1804502.81\n","total_cost: 58134.49\n","total_trades: 27146\n","Sharpe: 1.372\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 91          |\n","|    time_elapsed         | 1489        |\n","|    total_timesteps      | 186368      |\n","| train/                  |             |\n","|    approx_kl            | 0.018987358 |\n","|    clip_fraction        | 0.242       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.9       |\n","|    explained_variance   | 0.807       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 6.58        |\n","|    n_updates            | 900         |\n","|    policy_gradient_loss | -0.00863    |\n","|    reward               | -0.64131236 |\n","|    std                  | 1.14        |\n","|    value_loss           | 15.7        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 92          |\n","|    time_elapsed         | 1505        |\n","|    total_timesteps      | 188416      |\n","| train/                  |             |\n","|    approx_kl            | 0.026763301 |\n","|    clip_fraction        | 0.214       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -45         |\n","|    explained_variance   | 0.807       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 5.67        |\n","|    n_updates            | 910         |\n","|    policy_gradient_loss | -0.00804    |\n","|    reward               | 0.5704862   |\n","|    std                  | 1.14        |\n","|    value_loss           | 16.3        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 93          |\n","|    time_elapsed         | 1522        |\n","|    total_timesteps      | 190464      |\n","| train/                  |             |\n","|    approx_kl            | 0.029797629 |\n","|    clip_fraction        | 0.259       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -45         |\n","|    explained_variance   | 0.74        |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 8           |\n","|    n_updates            | 920         |\n","|    policy_gradient_loss | -0.0138     |\n","|    reward               | 0.6098732   |\n","|    std                  | 1.15        |\n","|    value_loss           | 12.1        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 94          |\n","|    time_elapsed         | 1539        |\n","|    total_timesteps      | 192512      |\n","| train/                  |             |\n","|    approx_kl            | 0.039320078 |\n","|    clip_fraction        | 0.327       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -45.1       |\n","|    explained_variance   | 0.746       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 8.49        |\n","|    n_updates            | 930         |\n","|    policy_gradient_loss | -0.00377    |\n","|    reward               | 1.9233522   |\n","|    std                  | 1.15        |\n","|    value_loss           | 12.7        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 95          |\n","|    time_elapsed         | 1555        |\n","|    total_timesteps      | 194560      |\n","| train/                  |             |\n","|    approx_kl            | 0.042732693 |\n","|    clip_fraction        | 0.367       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -45.1       |\n","|    explained_variance   | 0.683       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 4.79        |\n","|    n_updates            | 940         |\n","|    policy_gradient_loss | 0.00195     |\n","|    reward               | -1.9311274  |\n","|    std                  | 1.15        |\n","|    value_loss           | 11.1        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 96          |\n","|    time_elapsed         | 1571        |\n","|    total_timesteps      | 196608      |\n","| train/                  |             |\n","|    approx_kl            | 0.027920825 |\n","|    clip_fraction        | 0.236       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -45.1       |\n","|    explained_variance   | 0.754       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 4.92        |\n","|    n_updates            | 950         |\n","|    policy_gradient_loss | -0.0101     |\n","|    reward               | 0.45892298  |\n","|    std                  | 1.15        |\n","|    value_loss           | 14.6        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 97          |\n","|    time_elapsed         | 1586        |\n","|    total_timesteps      | 198656      |\n","| train/                  |             |\n","|    approx_kl            | 0.058466334 |\n","|    clip_fraction        | 0.323       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -45.1       |\n","|    explained_variance   | 0.778       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 6.45        |\n","|    n_updates            | 960         |\n","|    policy_gradient_loss | -0.000474   |\n","|    reward               | 0.38076562  |\n","|    std                  | 1.15        |\n","|    value_loss           | 13.8        |\n","-----------------------------------------\n","day: 1258, episode: 240\n","begin_total_asset: 1000000.00\n","end_total_asset: 2324573.51\n","total_reward: 1324573.51\n","total_cost: 74829.08\n","total_trades: 28255\n","Sharpe: 1.281\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 125         |\n","|    iterations           | 98          |\n","|    time_elapsed         | 1602        |\n","|    total_timesteps      | 200704      |\n","| train/                  |             |\n","|    approx_kl            | 0.027945856 |\n","|    clip_fraction        | 0.319       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -45.2       |\n","|    explained_variance   | 0.747       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 3.66        |\n","|    n_updates            | 970         |\n","|    policy_gradient_loss | -0.00888    |\n","|    reward               | -2.5205     |\n","|    std                  | 1.15        |\n","|    value_loss           | 10.5        |\n","-----------------------------------------\n","{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n","Using cpu device\n","Logging to results/td3\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 4          |\n","|    fps             | 30         |\n","|    time_elapsed    | 163        |\n","|    total_timesteps | 5036       |\n","| train/             |            |\n","|    actor_loss      | 22.3       |\n","|    critic_loss     | 2.83e+03   |\n","|    learning_rate   | 0.001      |\n","|    n_updates       | 3777       |\n","|    reward          | -1.3809705 |\n","-----------------------------------\n","day: 1258, episode: 250\n","begin_total_asset: 1000000.00\n","end_total_asset: 2337576.03\n","total_reward: 1337576.03\n","total_cost: 999.00\n","total_trades: 17612\n","Sharpe: 1.462\n","=================================\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 8          |\n","|    fps             | 26         |\n","|    time_elapsed    | 375        |\n","|    total_timesteps | 10072      |\n","| train/             |            |\n","|    actor_loss      | 14         |\n","|    critic_loss     | 52.4       |\n","|    learning_rate   | 0.001      |\n","|    n_updates       | 8813       |\n","|    reward          | -1.3809705 |\n","-----------------------------------\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 12         |\n","|    fps             | 25         |\n","|    time_elapsed    | 591        |\n","|    total_timesteps | 15108      |\n","| train/             |            |\n","|    actor_loss      | 11.6       |\n","|    critic_loss     | 21.9       |\n","|    learning_rate   | 0.001      |\n","|    n_updates       | 13849      |\n","|    reward          | -1.3809705 |\n","-----------------------------------\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 16         |\n","|    fps             | 24         |\n","|    time_elapsed    | 813        |\n","|    total_timesteps | 20144      |\n","| train/             |            |\n","|    actor_loss      | 11.2       |\n","|    critic_loss     | 3.8        |\n","|    learning_rate   | 0.001      |\n","|    n_updates       | 18885      |\n","|    reward          | -1.3809705 |\n","-----------------------------------\n","day: 1258, episode: 260\n","begin_total_asset: 1000000.00\n","end_total_asset: 2337576.03\n","total_reward: 1337576.03\n","total_cost: 999.00\n","total_trades: 17612\n","Sharpe: 1.462\n","=================================\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 20         |\n","|    fps             | 24         |\n","|    time_elapsed    | 1031       |\n","|    total_timesteps | 25180      |\n","| train/             |            |\n","|    actor_loss      | 13.2       |\n","|    critic_loss     | 13.8       |\n","|    learning_rate   | 0.001      |\n","|    n_updates       | 23921      |\n","|    reward          | -1.3809705 |\n","-----------------------------------\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 24         |\n","|    fps             | 24         |\n","|    time_elapsed    | 1255       |\n","|    total_timesteps | 30216      |\n","| train/             |            |\n","|    actor_loss      | 12.3       |\n","|    critic_loss     | 1.57       |\n","|    learning_rate   | 0.001      |\n","|    n_updates       | 28957      |\n","|    reward          | -1.3809705 |\n","-----------------------------------\n","day: 1258, episode: 270\n","begin_total_asset: 1000000.00\n","end_total_asset: 2337576.03\n","total_reward: 1337576.03\n","total_cost: 999.00\n","total_trades: 17612\n","Sharpe: 1.462\n","=================================\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 28         |\n","|    fps             | 23         |\n","|    time_elapsed    | 1483       |\n","|    total_timesteps | 35252      |\n","| train/             |            |\n","|    actor_loss      | 11.7       |\n","|    critic_loss     | 1.51       |\n","|    learning_rate   | 0.001      |\n","|    n_updates       | 33993      |\n","|    reward          | -1.3809705 |\n","-----------------------------------\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 32         |\n","|    fps             | 23         |\n","|    time_elapsed    | 1706       |\n","|    total_timesteps | 40288      |\n","| train/             |            |\n","|    actor_loss      | 10.6       |\n","|    critic_loss     | 0.559      |\n","|    learning_rate   | 0.001      |\n","|    n_updates       | 39029      |\n","|    reward          | -1.3809705 |\n","-----------------------------------\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 36         |\n","|    fps             | 23         |\n","|    time_elapsed    | 1929       |\n","|    total_timesteps | 45324      |\n","| train/             |            |\n","|    actor_loss      | 9.43       |\n","|    critic_loss     | 0.342      |\n","|    learning_rate   | 0.001      |\n","|    n_updates       | 44065      |\n","|    reward          | -1.3809705 |\n","-----------------------------------\n","day: 1258, episode: 280\n","begin_total_asset: 1000000.00\n","end_total_asset: 2337576.03\n","total_reward: 1337576.03\n","total_cost: 999.00\n","total_trades: 17612\n","Sharpe: 1.462\n","=================================\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 40         |\n","|    fps             | 23         |\n","|    time_elapsed    | 2154       |\n","|    total_timesteps | 50360      |\n","| train/             |            |\n","|    actor_loss      | 8.57       |\n","|    critic_loss     | 0.263      |\n","|    learning_rate   | 0.001      |\n","|    n_updates       | 49101      |\n","|    reward          | -1.3809705 |\n","-----------------------------------\n","{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n","Using cpu device\n","Logging to results/sac\n","----------------------------------\n","| time/              |           |\n","|    episodes        | 4         |\n","|    fps             | 23        |\n","|    time_elapsed    | 214       |\n","|    total_timesteps | 5036      |\n","| train/             |           |\n","|    actor_loss      | 192       |\n","|    critic_loss     | 4.17e+03  |\n","|    ent_coef        | 0.1       |\n","|    ent_coef_loss   | -52.9     |\n","|    learning_rate   | 0.0001    |\n","|    n_updates       | 4935      |\n","|    reward          | -1.170657 |\n","----------------------------------\n","day: 1258, episode: 290\n","begin_total_asset: 1000000.00\n","end_total_asset: 2049648.10\n","total_reward: 1049648.10\n","total_cost: 3518.73\n","total_trades: 22684\n","Sharpe: 1.086\n","=================================\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 8          |\n","|    fps             | 23         |\n","|    time_elapsed    | 435        |\n","|    total_timesteps | 10072      |\n","| train/             |            |\n","|    actor_loss      | 99.7       |\n","|    critic_loss     | 1.65e+03   |\n","|    ent_coef        | 0.0612     |\n","|    ent_coef_loss   | -75.4      |\n","|    learning_rate   | 0.0001     |\n","|    n_updates       | 9971       |\n","|    reward          | -1.0538679 |\n","-----------------------------------\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 12         |\n","|    fps             | 22         |\n","|    time_elapsed    | 663        |\n","|    total_timesteps | 15108      |\n","| train/             |            |\n","|    actor_loss      | 42         |\n","|    critic_loss     | 44.8       |\n","|    ent_coef        | 0.0376     |\n","|    ent_coef_loss   | -78.4      |\n","|    learning_rate   | 0.0001     |\n","|    n_updates       | 15007      |\n","|    reward          | -1.2802418 |\n","-----------------------------------\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 16         |\n","|    fps             | 22         |\n","|    time_elapsed    | 891        |\n","|    total_timesteps | 20144      |\n","| train/             |            |\n","|    actor_loss      | 35.1       |\n","|    critic_loss     | 103        |\n","|    ent_coef        | 0.0231     |\n","|    ent_coef_loss   | -68.7      |\n","|    learning_rate   | 0.0001     |\n","|    n_updates       | 20043      |\n","|    reward          | -1.1764334 |\n","-----------------------------------\n","day: 1258, episode: 300\n","begin_total_asset: 1000000.00\n","end_total_asset: 2136692.04\n","total_reward: 1136692.04\n","total_cost: 2411.86\n","total_trades: 23695\n","Sharpe: 1.176\n","=================================\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 20         |\n","|    fps             | 22         |\n","|    time_elapsed    | 1118       |\n","|    total_timesteps | 25180      |\n","| train/             |            |\n","|    actor_loss      | 39.1       |\n","|    critic_loss     | 563        |\n","|    ent_coef        | 0.0142     |\n","|    ent_coef_loss   | -73.6      |\n","|    learning_rate   | 0.0001     |\n","|    n_updates       | 25079      |\n","|    reward          | -1.2795287 |\n","-----------------------------------\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 24         |\n","|    fps             | 22         |\n","|    time_elapsed    | 1349       |\n","|    total_timesteps | 30216      |\n","| train/             |            |\n","|    actor_loss      | 27.8       |\n","|    critic_loss     | 230        |\n","|    ent_coef        | 0.00867    |\n","|    ent_coef_loss   | -69        |\n","|    learning_rate   | 0.0001     |\n","|    n_updates       | 30115      |\n","|    reward          | -1.2338532 |\n","-----------------------------------\n","day: 1258, episode: 310\n","begin_total_asset: 1000000.00\n","end_total_asset: 2044429.19\n","total_reward: 1044429.19\n","total_cost: 2296.29\n","total_trades: 22947\n","Sharpe: 1.089\n","=================================\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 28         |\n","|    fps             | 22         |\n","|    time_elapsed    | 1577       |\n","|    total_timesteps | 35252      |\n","| train/             |            |\n","|    actor_loss      | 20.9       |\n","|    critic_loss     | 1.71       |\n","|    ent_coef        | 0.00526    |\n","|    ent_coef_loss   | -82.8      |\n","|    learning_rate   | 0.0001     |\n","|    n_updates       | 35151      |\n","|    reward          | -1.1402736 |\n","-----------------------------------\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 32         |\n","|    fps             | 22         |\n","|    time_elapsed    | 1811       |\n","|    total_timesteps | 40288      |\n","| train/             |            |\n","|    actor_loss      | 18.7       |\n","|    critic_loss     | 1.86       |\n","|    ent_coef        | 0.00329    |\n","|    ent_coef_loss   | -52.5      |\n","|    learning_rate   | 0.0001     |\n","|    n_updates       | 40187      |\n","|    reward          | -1.1050065 |\n","-----------------------------------\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 36         |\n","|    fps             | 22         |\n","|    time_elapsed    | 2043       |\n","|    total_timesteps | 45324      |\n","| train/             |            |\n","|    actor_loss      | 16.3       |\n","|    critic_loss     | 0.777      |\n","|    ent_coef        | 0.00212    |\n","|    ent_coef_loss   | -36        |\n","|    learning_rate   | 0.0001     |\n","|    n_updates       | 45223      |\n","|    reward          | -1.0243509 |\n","-----------------------------------\n","day: 1258, episode: 320\n","begin_total_asset: 1000000.00\n","end_total_asset: 1917593.67\n","total_reward: 917593.67\n","total_cost: 2412.04\n","total_trades: 23683\n","Sharpe: 1.009\n","=================================\n","------------------------------------\n","| time/              |             |\n","|    episodes        | 40          |\n","|    fps             | 22          |\n","|    time_elapsed    | 2278        |\n","|    total_timesteps | 50360       |\n","| train/             |             |\n","|    actor_loss      | 16.9        |\n","|    critic_loss     | 3.29        |\n","|    ent_coef        | 0.00148     |\n","|    ent_coef_loss   | -7.79       |\n","|    learning_rate   | 0.0001      |\n","|    n_updates       | 50259       |\n","|    reward          | -0.99339384 |\n","------------------------------------\n"]}],"source":["!pip install swig\n","!pip install wrds\n","!pip install pyportfolioopt\n","\n","## install finrl library\n","!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n","\n","import finrl\n","import sys\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import datetime\n","import yfinance as yf\n","import os\n","\n","from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n","from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n","from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n","from finrl.agents.stablebaselines3.models import DRLAgent\n","from stable_baselines3.common.logger import configure\n","from finrl import config_tickers\n","from finrl.main import check_and_make_directories\n","from finrl.config import TRAINED_MODEL_DIR, RESULTS_DIR\n","from stable_baselines3 import A2C, DDPG, PPO, SAC, TD3\n","get_ipython().run_line_magic('matplotlib', 'inline')\n","from finrl.config import INDICATORS\n","\n","\n","check_and_make_directories([TRAINED_MODEL_DIR])\n","\n","\n","import itertools\n","\n","config_tickers.DOW_30_TICKER\n","\n","\n","\n","TRAIN_START_DATE = '2013-01-01' #start date of training data\n","TRAIN_END_DATE = '2018-01-01'   #end date of training data\n","TRADE_START_DATE = '2018-01-01' #start date of trading data\n","TRADE_END_DATE = '2022-12-31'   #end date of trading data\n","\n","df_raw = YahooDownloader(start_date = TRAIN_START_DATE,\n","                     end_date = TRADE_END_DATE,\n","                     ticker_list = config_tickers.DOW_30_TICKER).fetch_data()\n","df_raw.head()\n","\n","#Preprocess Data\n","fe = FeatureEngineer(use_technical_indicator=True,\n","                     tech_indicator_list = INDICATORS,\n","                     use_vix=True,\n","                     use_turbulence=True,\n","                     user_defined_feature = False)\n","processed = fe.preprocess_data(df_raw)\n","\n","list_ticker = processed[\"tic\"].unique().tolist()\n","list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n","combination = list(itertools.product(list_date,list_ticker))\n","\n","processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n","processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n","processed_full = processed_full.sort_values(['date','tic'])\n","processed_full = processed_full.fillna(0)\n","processed_full.head()\n","\n","#Split the data for training and trading\n","train = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE)\n","trade = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE)\n","print(len(train))\n","print(len(trade))\n","\n","train.to_csv('train_data.csv')\n","trade.to_csv('trade_data.csv')\n","train = pd.read_csv('train_data.csv')\n","train = train.set_index(train.columns[0])\n","train.index.names = ['']\n","\n","#Construct the environment\n","stock_dimension = len(train.tic.unique())\n","state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n","print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n","\n","buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n","num_stock_shares = [0] * stock_dimension\n","\n","env_kwargs = {\n","    \"hmax\": 100,\n","    \"initial_amount\": 1000000,\n","    \"num_stock_shares\": num_stock_shares,\n","    \"buy_cost_pct\": buy_cost_list,\n","    \"sell_cost_pct\": sell_cost_list,\n","    \"state_space\": state_space,\n","    \"stock_dim\": stock_dimension,\n","    \"tech_indicator_list\": INDICATORS,\n","    \"action_space\": stock_dimension,\n","    \"reward_scaling\": 1e-4\n","}\n","e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n","\n","#Environment for training\n","env_train, _ = e_train_gym.get_sb_env()\n","print(type(env_train))\n","\n","#Train DRL Agents\n","agent = DRLAgent(env = env_train)\n","\n","# Set the corresponding values to 'True' for the algorithms that you want to use\n","if_using_a2c = True\n","if_using_ddpg = True\n","if_using_ppo = True\n","if_using_td3 = True\n","if_using_sac = True\n","\n","# ### Agent 1: A2C\n","\n","agent = DRLAgent(env = env_train)\n","model_a2c = agent.get_model(\"a2c\")\n","\n","if if_using_a2c:\n","  # set up logger\n","  tmp_path = RESULTS_DIR + '/a2c'\n","  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n","  # Set new logger\n","  model_a2c.set_logger(new_logger_a2c)\n","trained_a2c = agent.train_model(model=model_a2c,\n","                             tb_log_name='a2c',\n","                             total_timesteps=50000) if if_using_a2c else None\n","trained_a2c.save(TRAINED_MODEL_DIR + \"/agent_a2c\") if if_using_a2c else None\n","\n","# ### Agent 2: DDPG\n","agent = DRLAgent(env = env_train)\n","model_ddpg = agent.get_model(\"ddpg\")\n","\n","if if_using_ddpg:\n","  # set up logger\n","  tmp_path = RESULTS_DIR + '/ddpg'\n","  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n","  # Set new logger\n","  model_ddpg.set_logger(new_logger_ddpg)\n","\n","trained_ddpg = agent.train_model(model=model_ddpg,\n","                             tb_log_name='ddpg',\n","                             total_timesteps=50000) if if_using_ddpg else None\n","\n","trained_ddpg.save(TRAINED_MODEL_DIR + \"/agent_ddpg\") if if_using_ddpg else None\n","\n","# ### Agent 3: PPO\n","agent = DRLAgent(env = env_train)\n","PPO_PARAMS = {\n","    \"n_steps\": 2048,\n","    \"ent_coef\": 0.01,\n","    \"learning_rate\": 0.00025,\n","    \"batch_size\": 128,\n","}\n","model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n","\n","if if_using_ppo:\n","  # set up logger\n","  tmp_path = RESULTS_DIR + '/ppo'\n","  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n","  # Set new logger\n","  model_ppo.set_logger(new_logger_ppo)\n","\n","\n","trained_ppo = agent.train_model(model=model_ppo,\n","                             tb_log_name='ppo',\n","                             total_timesteps=200000) if if_using_ppo else None\n","\n","\n","trained_ppo.save(TRAINED_MODEL_DIR + \"/agent_ppo\") if if_using_ppo else None\n","\n","# ### Agent 4: TD3\n","\n","\n","agent = DRLAgent(env = env_train)\n","TD3_PARAMS = {\"batch_size\": 100,\n","              \"buffer_size\": 1000000,\n","              \"learning_rate\": 0.001}\n","\n","model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n","\n","if if_using_td3:\n","  # set up logger\n","  tmp_path = RESULTS_DIR + '/td3'\n","  new_logger_td3 = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n","  # Set new logger\n","  model_td3.set_logger(new_logger_td3)\n","\n","\n","\n","trained_td3 = agent.train_model(model=model_td3,\n","                             tb_log_name='td3',\n","                             total_timesteps=50000) if if_using_td3 else None\n","\n","\n","\n","trained_td3.save(TRAINED_MODEL_DIR + \"/agent_td3\") if if_using_td3 else None\n","\n","#Agent 5: SAC\n","agent = DRLAgent(env = env_train)\n","SAC_PARAMS = {\n","    \"batch_size\": 128,\n","    \"buffer_size\": 100000,\n","    \"learning_rate\": 0.0001,\n","    \"learning_starts\": 100,\n","    \"ent_coef\": \"auto_0.1\",\n","}\n","\n","model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n","\n","if if_using_sac:\n","  # set up logger\n","  tmp_path = RESULTS_DIR + '/sac'\n","  new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n","  # Set new logger\n","  model_sac.set_logger(new_logger_sac)\n","trained_sac = agent.train_model(model=model_sac,\n","                             tb_log_name='sac',\n","                             total_timesteps=70000) if if_using_sac else None\n","trained_sac.save(TRAINED_MODEL_DIR + \"/agent_sac\") if if_using_sac else None\n","\n","# # Part 2. Backtesting\n","train = pd.read_csv('train_data.csv')\n","trade = pd.read_csv('trade_data.csv')\n","train = train.set_index(train.columns[0])\n","train.index.names = ['']\n","trade = trade.set_index(trade.columns[0])\n","trade.index.names = ['']\n","\n","if_using_a2c = True\n","if_using_ddpg = True\n","if_using_ppo = True\n","if_using_td3 = True\n","if_using_sac = True\n","\n","# Load the agents\n","trained_a2c = A2C.load(\"trained_models/agent_a2c\") if if_using_a2c else None\n","trained_ddpg = DDPG.load(\"trained_models/agent_ddpg\") if if_using_ddpg else None\n","trained_ppo = PPO.load(\"trained_models/agent_ppo\") if if_using_ppo else None\n","trained_td3 = TD3.load(\"trained_models/agent_td3\") if if_using_td3 else None\n","trained_sac = SAC.load(\"trained_models/agent_sac\") if if_using_sac else None\n","\n","stock_dimension = len(trade.tic.unique())\n","state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n","print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n","\n","buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n","num_stock_shares = [0] * stock_dimension\n","\n","env_kwargs = {\n","    \"hmax\": 100,\n","    \"initial_amount\": 1000000,\n","    \"num_stock_shares\": num_stock_shares,\n","    \"buy_cost_pct\": buy_cost_list,\n","    \"sell_cost_pct\": sell_cost_list,\n","    \"state_space\": state_space,\n","    \"stock_dim\": stock_dimension,\n","    \"tech_indicator_list\": INDICATORS,\n","    \"action_space\": stock_dimension,\n","    \"reward_scaling\": 1e-4\n","}\n","\n","e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n","# env_trade, obs_trade = e_trade_gym.get_sb_env()\n","\n","df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n","    model=trained_a2c,\n","    environment = e_trade_gym) if if_using_a2c else (None, None)\n","\n","df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n","    model=trained_ddpg,\n","    environment = e_trade_gym) if if_using_ddpg else (None, None)\n","\n","df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n","    model=trained_ppo,\n","    environment = e_trade_gym) if if_using_ppo else (None, None)\n","\n","df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n","    model=trained_td3,\n","    environment = e_trade_gym) if if_using_td3 else (None, None)\n","\n","df_account_value_sac, df_actions_sac = DRLAgent.DRL_prediction(\n","    model=trained_sac,\n","    environment = e_trade_gym) if if_using_sac else (None, None)\n","\n","#Mean Variance Optimization\n","def process_df_for_mvo(df):\n","  df = df.sort_values(['date','tic'],ignore_index=True)[['date','tic','close']]\n","  fst = df\n","  fst = fst.iloc[0:stock_dimension, :]\n","  tic = fst['tic'].tolist()\n","\n","  mvo = pd.DataFrame()\n","\n","  for k in range(len(tic)):\n","    mvo[tic[k]] = 0\n","\n","  for i in range(df.shape[0]//stock_dimension):\n","    n = df\n","    n = n.iloc[i * stock_dimension:(i+1) * stock_dimension, :]\n","    date = n['date'][i*stock_dimension]\n","    mvo.loc[date] = n['close'].tolist()\n","\n","  return mvo\n","\n","#Helper functions for mean returns and variance-covariance matrix\n","\n","def StockReturnsComputing(StockPrice, Rows, Columns):\n","  import numpy as np\n","  StockReturn = np.zeros([Rows-1, Columns])\n","  for j in range(Columns):        # j: Assets\n","    for i in range(Rows-1):     # i: Daily Prices\n","      StockReturn[i,j]=((StockPrice[i+1, j]-StockPrice[i,j])/StockPrice[i,j])* 100\n","\n","  return StockReturn\n","\n","# ### Calculate the weights for mean-variance\n","StockData = process_df_for_mvo(train)\n","TradeData = process_df_for_mvo(trade)\n","\n","TradeData.to_numpy()\n","\n","#compute asset returns\n","arStockPrices = np.asarray(StockData)\n","[Rows, Cols]=arStockPrices.shape\n","arReturns = StockReturnsComputing(arStockPrices, Rows, Cols)\n","\n","#compute mean returns and variance covariance matrix of returns\n","meanReturns = np.mean(arReturns, axis = 0)\n","covReturns = np.cov(arReturns, rowvar=False)\n","\n","#set precision for printing results\n","np.set_printoptions(precision=3, suppress = True)\n","\n","#display mean returns and variance-covariance matrix of returns\n","print('Mean returns of assets in k-portfolio 1\\n', meanReturns)\n","print('Variance-Covariance matrix of returns\\n', covReturns)\n","\n","from pypfopt.efficient_frontier import EfficientFrontier\n","\n","ef_mean = EfficientFrontier(meanReturns, covReturns, weight_bounds=(0, 0.5))\n","raw_weights_mean = ef_mean.max_sharpe()\n","cleaned_weights_mean = ef_mean.clean_weights()\n","mvo_weights = np.array([1000000 * cleaned_weights_mean[i] for i in range(29)])\n","mvo_weights\n","\n","LastPrice = np.array([1/p for p in StockData.tail(1).to_numpy()[0]])\n","Initial_Portfolio = np.multiply(mvo_weights, LastPrice)\n","Initial_Portfolio\n","\n","Portfolio_Assets = TradeData @ Initial_Portfolio\n","MVO_result = pd.DataFrame(Portfolio_Assets, columns=[\"Mean Var\"])\n","\n","df_dji = YahooDownloader(start_date = TRADE_START_DATE,\n","                     end_date = TRADE_END_DATE,\n","                     ticker_list = ['dji']).fetch_data()\n","\n","df_dji = df_dji[['date','close']]\n","fst_day = df_dji['close'][0]\n","dji = pd.merge(df_dji['date'], df_dji['close'].div(fst_day).mul(1000000),\n","               how='outer', left_index=True, right_index=True).set_index('date')\n","\n","df_result_a2c = df_account_value_a2c.set_index(df_account_value_a2c.columns[0]) if if_using_a2c else None\n","df_result_ddpg = df_account_value_ddpg.set_index(df_account_value_ddpg.columns[0]) if if_using_ddpg else None\n","df_result_ppo = df_account_value_ppo.set_index(df_account_value_ppo.columns[0]) if if_using_ppo else None\n","df_result_td3 = df_account_value_td3.set_index(df_account_value_td3.columns[0]) if if_using_td3 else None\n","df_result_sac = df_account_value_sac.set_index(df_account_value_sac.columns[0]) if if_using_sac else None\n","result = pd.DataFrame()\n","\n","if if_using_a2c: result = pd.merge(result, df_result_a2c, how='outer', left_index=True, right_index=True)\n","if if_using_ddpg: result = pd.merge(result, df_result_ddpg, how='outer', left_index=True, right_index=True)\n","if if_using_ppo: result = pd.merge(result, df_result_ppo, how='outer', left_index=True, right_index=True)\n","if if_using_td3: result = pd.merge(result, df_result_td3, how='outer', left_index=True, right_index=True)\n","if if_using_sac: result = pd.merge(result, df_result_sac, how='outer', left_index=True, right_index=True)\n","result = pd.merge(result, MVO_result, how='outer', left_index=True, right_index=True)\n","result = pd.merge(result, dji, how='outer', left_index=True, right_index=True).fillna(method='bfill')\n","\n","\n"]},{"cell_type":"code","source":["col_name = []\n","col_name.append('A2C') if if_using_a2c else None\n","col_name.append('DDPG') if if_using_ddpg else None\n","col_name.append('PPO') if if_using_ppo else None\n","col_name.append('TD3') if if_using_td3 else None\n","col_name.append('SAC') if if_using_sac else None\n","col_name.append('Mean Var')\n","col_name.append('djia')\n","result.columns = col_name\n","result"],"metadata":{"id":"J0nF7KtHZ_zq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.rcParams[\"figure.figsize\"] = (15,5)\n","plt.figure()\n","result.plot()"],"metadata":{"id":"Hz-OYS0WaBiP"},"execution_count":null,"outputs":[]}]}